{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5dc2856",
   "metadata": {
    "_cell_guid": "18d9431e-6356-4b78-af8f-238e59032dac",
    "_uuid": "dab3e625-3049-4356-805c-1d92055fda90",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-09-30T10:04:08.822976Z",
     "iopub.status.busy": "2025-09-30T10:04:08.822689Z",
     "iopub.status.idle": "2025-09-30T10:05:39.299521Z",
     "shell.execute_reply": "2025-09-30T10:05:39.298552Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 90.484235,
     "end_time": "2025-09-30T10:05:39.301270",
     "exception": false,
     "start_time": "2025-09-30T10:04:08.817035",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ultralytics\r\n",
      "  Downloading ultralytics-8.3.203-py3-none-any.whl.metadata (37 kB)\r\n",
      "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.26.4)\r\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (3.7.5)\r\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.11.0.86)\r\n",
      "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (11.1.0)\r\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (6.0.2)\r\n",
      "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.32.3)\r\n",
      "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.15.2)\r\n",
      "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.5.1+cu124)\r\n",
      "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.20.1+cu124)\r\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ultralytics) (7.0.0)\r\n",
      "Requirement already satisfied: polars in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.9.0)\r\n",
      "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\r\n",
      "  Downloading ultralytics_thop-2.0.17-py3-none-any.whl.metadata (14 kB)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.1)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.56.0)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.8)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\r\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.1)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.0->ultralytics) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.0->ultralytics) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.0->ultralytics) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.0->ultralytics) (2025.1.0)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.0->ultralytics) (2022.1.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.0->ultralytics) (2.4.1)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.4.1)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2.3.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2025.1.31)\r\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.18.0)\r\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (4.13.1)\r\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.4.2)\r\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\r\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2025.3.2)\r\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\r\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\r\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\r\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.8.0->ultralytics)\r\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.8.0->ultralytics)\r\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.8.0->ultralytics)\r\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.8.0->ultralytics)\r\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.8.0->ultralytics)\r\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.8.0->ultralytics)\r\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\r\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2.21.5)\r\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\r\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\r\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.1.0)\r\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\r\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\r\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.23.0->ultralytics) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.23.0->ultralytics) (2022.1.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.23.0->ultralytics) (1.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.23.0->ultralytics) (2024.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.23.0->ultralytics) (2024.2.0)\r\n",
      "Downloading ultralytics-8.3.203-py3-none-any.whl (1.1 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m29.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m68.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading ultralytics_thop-2.0.17-py3-none-any.whl (28 kB)\r\n",
      "Installing collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, ultralytics-thop, ultralytics\r\n",
      "  Attempting uninstall: nvidia-nvjitlink-cu12\r\n",
      "    Found existing installation: nvidia-nvjitlink-cu12 12.8.93\r\n",
      "    Uninstalling nvidia-nvjitlink-cu12-12.8.93:\r\n",
      "      Successfully uninstalled nvidia-nvjitlink-cu12-12.8.93\r\n",
      "  Attempting uninstall: nvidia-curand-cu12\r\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.9.90\r\n",
      "    Uninstalling nvidia-curand-cu12-10.3.9.90:\r\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.9.90\r\n",
      "  Attempting uninstall: nvidia-cufft-cu12\r\n",
      "    Found existing installation: nvidia-cufft-cu12 11.3.3.83\r\n",
      "    Uninstalling nvidia-cufft-cu12-11.3.3.83:\r\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.3.3.83\r\n",
      "  Attempting uninstall: nvidia-cublas-cu12\r\n",
      "    Found existing installation: nvidia-cublas-cu12 12.8.4.1\r\n",
      "    Uninstalling nvidia-cublas-cu12-12.8.4.1:\r\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.8.4.1\r\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\r\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.8.93\r\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.8.93:\r\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.8.93\r\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\r\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\r\n",
      "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\r\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\r\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\r\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.7.3.90\r\n",
      "    Uninstalling nvidia-cusolver-cu12-11.7.3.90:\r\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.7.3.90\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "pylibcugraph-cu12 24.12.0 requires pylibraft-cu12==24.12.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\r\n",
      "pylibcugraph-cu12 24.12.0 requires rmm-cu12==24.12.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 ultralytics-8.3.203 ultralytics-thop-2.0.17\r\n",
      "Collecting torchtoolbox\r\n",
      "  Downloading torchtoolbox-0.1.8.2-py3-none-any.whl.metadata (15 kB)\r\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchtoolbox) (1.26.4)\r\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torchtoolbox) (4.67.1)\r\n",
      "Requirement already satisfied: pyarrow in /usr/local/lib/python3.11/dist-packages (from torchtoolbox) (19.0.1)\r\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from torchtoolbox) (1.17.0)\r\n",
      "Collecting lmdb (from torchtoolbox)\r\n",
      "  Downloading lmdb-1.7.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.3 kB)\r\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from torchtoolbox) (1.2.2)\r\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from torchtoolbox) (1.15.2)\r\n",
      "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (from torchtoolbox) (4.11.0.86)\r\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from torchtoolbox) (6.0.2)\r\n",
      "Requirement already satisfied: tensorboard in /usr/local/lib/python3.11/dist-packages (from torchtoolbox) (2.18.0)\r\n",
      "Requirement already satisfied: prettytable in /usr/local/lib/python3.11/dist-packages (from torchtoolbox) (3.14.0)\r\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (from torchtoolbox) (4.51.1)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->torchtoolbox) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->torchtoolbox) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->torchtoolbox) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->torchtoolbox) (2025.1.0)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->torchtoolbox) (2022.1.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->torchtoolbox) (2.4.1)\r\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prettytable->torchtoolbox) (0.2.13)\r\n",
      "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->torchtoolbox) (1.4.2)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->torchtoolbox) (3.6.0)\r\n",
      "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.11/dist-packages (from tensorboard->torchtoolbox) (1.4.0)\r\n",
      "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.11/dist-packages (from tensorboard->torchtoolbox) (1.70.0)\r\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard->torchtoolbox) (3.7)\r\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorboard->torchtoolbox) (24.2)\r\n",
      "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.11/dist-packages (from tensorboard->torchtoolbox) (3.20.3)\r\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard->torchtoolbox) (75.1.0)\r\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard->torchtoolbox) (0.7.2)\r\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard->torchtoolbox) (3.1.3)\r\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers->torchtoolbox) (3.18.0)\r\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers->torchtoolbox) (0.30.2)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers->torchtoolbox) (2024.11.6)\r\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers->torchtoolbox) (2.32.3)\r\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers->torchtoolbox) (0.21.0)\r\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers->torchtoolbox) (0.5.2)\r\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers->torchtoolbox) (2025.3.2)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers->torchtoolbox) (4.13.1)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard->torchtoolbox) (3.0.2)\r\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torchtoolbox) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torchtoolbox) (2022.1.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->torchtoolbox) (1.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->torchtoolbox) (2024.2.0)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers->torchtoolbox) (3.4.1)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers->torchtoolbox) (3.10)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers->torchtoolbox) (2.3.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers->torchtoolbox) (2025.1.31)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->torchtoolbox) (2024.2.0)\r\n",
      "Downloading torchtoolbox-0.1.8.2-py3-none-any.whl (84 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.0/85.0 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading lmdb-1.7.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (299 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m299.6/299.6 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: lmdb, torchtoolbox\r\n",
      "Successfully installed lmdb-1.7.3 torchtoolbox-0.1.8.2\r\n"
     ]
    }
   ],
   "source": [
    "!pip install ultralytics\n",
    "!pip install torchtoolbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c7c1987",
   "metadata": {
    "_cell_guid": "0872ef46-9271-4236-85f5-d65741650e7a",
    "_uuid": "105346c6-993e-4e09-b190-227ebe1306fa",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-09-30T10:05:39.347302Z",
     "iopub.status.busy": "2025-09-30T10:05:39.346690Z",
     "iopub.status.idle": "2025-09-30T10:05:48.459794Z",
     "shell.execute_reply": "2025-09-30T10:05:48.459045Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 9.137803,
     "end_time": "2025-09-30T10:05:48.461333",
     "exception": false,
     "start_time": "2025-09-30T10:05:39.323530",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new Ultralytics Settings v0.0.6 file ✅ \n",
      "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
      "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from ultralytics import YOLO\n",
    "from torch.nn import MultiheadAttention\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import random\n",
    "import os\n",
    "from torch.utils.data import Dataset, DataLoader, Sampler, Subset, SubsetRandomSampler\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from torchtoolbox.tools import mixup_data, mixup_criterion\n",
    "from torch.utils.data import random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b31cccbe",
   "metadata": {
    "_cell_guid": "7bd22c72-d234-455b-a024-878909138939",
    "_uuid": "e016824d-da0c-4644-8dfa-3594e1b4eb19",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-09-30T10:05:48.506144Z",
     "iopub.status.busy": "2025-09-30T10:05:48.505237Z",
     "iopub.status.idle": "2025-09-30T10:05:48.511375Z",
     "shell.execute_reply": "2025-09-30T10:05:48.510635Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.029525,
     "end_time": "2025-09-30T10:05:48.512753",
     "exception": false,
     "start_time": "2025-09-30T10:05:48.483228",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "provinces = [\"皖\", \"沪\", \"津\", \"渝\", \"冀\", \"晋\", \"蒙\", \"辽\", \"吉\", \"黑\", \"苏\", \"浙\", \"京\", \"闽\", \"赣\", \"鲁\", \"豫\", \"鄂\", \"湘\", \"粤\", \"桂\", \"琼\", \"川\", \"贵\", \"云\", \"藏\", \"陕\", \"甘\", \"青\", \"宁\", \"新\", \"警\", \"学\", \"O\"]\n",
    "alphabets = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'J', 'K', 'L', 'M', 'N', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W',\n",
    "             'X', 'Y', 'Z', 'O']\n",
    "ads = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'J', 'K', 'L', 'M', 'N', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X',\n",
    "       'Y', 'Z', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'O']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82567b32",
   "metadata": {
    "_cell_guid": "43e3a590-e306-413c-adf3-c31d1ff2e354",
    "_uuid": "c170e629-54ef-4e77-a7d7-901e88a50121",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-09-30T10:05:48.559048Z",
     "iopub.status.busy": "2025-09-30T10:05:48.558402Z",
     "iopub.status.idle": "2025-09-30T10:05:48.662396Z",
     "shell.execute_reply": "2025-09-30T10:05:48.661542Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.129357,
     "end_time": "2025-09-30T10:05:48.663697",
     "exception": false,
     "start_time": "2025-09-30T10:05:48.534340",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "CHARACTERS = [\n",
    "    \"皖\",\"沪\",\"津\",\"渝\",\"冀\",\"晋\",\"蒙\",\"辽\",\"吉\",\"黑\",\"苏\",\"浙\",\"京\",\"闽\",\"赣\",\"鲁\",\"豫\",\"鄂\",\"湘\",\"粤\",\"桂\",\"琼\",\"川\",\"贵\",\"云\",\"藏\",\"陕\",\"甘\",\"青\",\"宁\",\"新\",\"警\",\"学\",\"O\",\n",
    "    \"A\",\"B\",\"C\",\"D\",\"E\",\"F\",\"G\",\"H\",\"J\",\"K\",\"L\",\"M\",\"N\",\"P\",\"Q\",\"R\",\"S\",\"T\",\"U\",\"V\",\"W\",\"X\",\"Y\",\"Z\",\n",
    "    \"0\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\"]\n",
    "SOS_TOKEN = len(CHARACTERS)  # SOS token là chỉ số ngay sau ký tự cuối cùng\n",
    "EOS_TOKEN = len(CHARACTERS) + 1\n",
    "PAD_TOKEN = len(CHARACTERS) + 2\n",
    "NUM_CLASSES = len(CHARACTERS) + 3  # Tổng số lớp: ký tự + SOS + EOS + PAD\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "#--- Utility functions ---\n",
    "def index_to_char(indices, include_special_tokens=False):\n",
    "    result = []\n",
    "    for i in indices:\n",
    "        i = i.item() if torch.is_tensor(i) else i\n",
    "        if i == SOS_TOKEN:\n",
    "            if include_special_tokens: result.append('[SOS]')\n",
    "        elif i == EOS_TOKEN:\n",
    "            if include_special_tokens: result.append('[EOS]')\n",
    "            break\n",
    "        elif 0 <= i < len(CHARACTERS):\n",
    "            result.append(CHARACTERS[i])\n",
    "        else:\n",
    "            if include_special_tokens or i not in [SOS_TOKEN, EOS_TOKEN]:\n",
    "                result.append(f'[UNK_{i}]')\n",
    "    return ''.join(result)\n",
    "\n",
    "def char_to_indices(text):\n",
    "    indices = [SOS_TOKEN]\n",
    "    for c in text:\n",
    "        if c in CHARACTERS:\n",
    "            indices.append(CHARACTERS.index(c))\n",
    "    indices.append(EOS_TOKEN)\n",
    "    return torch.tensor(indices, dtype=torch.long)\n",
    "\n",
    "#--- Early Stopping ---\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=10, min_delta=0.0, monitor_metric='val_acc', mode='max', verbose=True):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.monitor_metric = monitor_metric\n",
    "        self.mode = mode\n",
    "        self.verbose = verbose\n",
    "\n",
    "        if self.mode == 'min':\n",
    "            self.best_metric_val = np.Inf\n",
    "        else:\n",
    "            self.best_metric_val = -np.Inf\n",
    "        self.counter = 0\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, current_metric_val):\n",
    "        improved = False\n",
    "        if self.mode == 'min':\n",
    "            if current_metric_val < self.best_metric_val - self.min_delta:\n",
    "                self.best_metric_val = current_metric_val\n",
    "                improved = True\n",
    "        else:\n",
    "            if current_metric_val > self.best_metric_val + self.min_delta:\n",
    "                self.best_metric_val = current_metric_val\n",
    "                improved = True\n",
    "        \n",
    "        if improved:\n",
    "            self.counter = 0\n",
    "            if self.verbose:\n",
    "                print(f\"EarlyStopping: New best {self.monitor_metric}: {self.best_metric_val:.4f}\")\n",
    "        else:\n",
    "            self.counter += 1\n",
    "\n",
    "        if self.verbose and self.counter > 0 and not improved:\n",
    "            print(f\"EarlyStopping counter: {self.counter}/{self.patience} (Best {self.monitor_metric}: {self.best_metric_val:.4f})\")\n",
    "        if self.counter >= self.patience:\n",
    "            self.early_stop = True\n",
    "            if self.verbose:\n",
    "                print(f\"Early stopping triggered for {self.monitor_metric}.\")\n",
    "        return self.counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "82638a6b",
   "metadata": {
    "_cell_guid": "918f158d-3dba-411c-a5a5-39cacd6e7bde",
    "_uuid": "5929e625-7e5c-4427-a90f-49545e93fbfd",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-09-30T10:05:48.707929Z",
     "iopub.status.busy": "2025-09-30T10:05:48.707611Z",
     "iopub.status.idle": "2025-09-30T10:05:48.714956Z",
     "shell.execute_reply": "2025-09-30T10:05:48.714206Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.030881,
     "end_time": "2025-09-30T10:05:48.716168",
     "exception": false,
     "start_time": "2025-09-30T10:05:48.685287",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#--- YOLO ---\n",
    "class YoloBackbone(nn.Module):\n",
    "    def __init__(self, model_path, target_feature_layer_index=9):\n",
    "        super().__init__()\n",
    "        _temp_yolo_instance = YOLO(model_path)\n",
    "        self.yolo_detection_model = _temp_yolo_instance.model\n",
    "        self.yolo_detection_model.to(DEVICE)\n",
    "        self.target_feature_layer_index = target_feature_layer_index\n",
    "\n",
    "        for name, param in self.yolo_detection_model.named_parameters():\n",
    "            param.requires_grad = True\n",
    "        \n",
    "        self._hook_handle = None\n",
    "        self._fmap_out_hook = []\n",
    "        \n",
    "        self._register_hook()\n",
    "\n",
    "    def _hook_fn_extractor(self, module, input_val, output_val):\n",
    "        if isinstance(output_val, torch.Tensor):\n",
    "            self._fmap_out_hook.append(output_val)\n",
    "        elif isinstance(output_val, (list, tuple)):\n",
    "            for item in output_val:\n",
    "                if isinstance(item, torch.Tensor):\n",
    "                    self._fmap_out_hook.append(item)\n",
    "                    break\n",
    "\n",
    "    def _register_hook(self):\n",
    "        layer_to_hook = self.yolo_detection_model.model[self.target_feature_layer_index]\n",
    "        self._hook_handle = layer_to_hook.register_forward_hook(self._hook_fn_extractor)\n",
    "\n",
    "    def _remove_hook(self):\n",
    "        if self._hook_handle:\n",
    "            self._hook_handle.remove()\n",
    "            self._hook_handle = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        self._fmap_out_hook.clear()\n",
    "        _ = self.yolo_detection_model(x)\n",
    "        out_tensor = self._fmap_out_hook[0]\n",
    "        return out_tensor if out_tensor.dim() == 4 else out_tensor.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a0e5941",
   "metadata": {
    "_cell_guid": "53861469-ab9b-48cf-828e-a5b0a6ff2f1d",
    "_uuid": "44b41d70-014e-4fb6-b4c8-629305acdc66",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-09-30T10:05:48.814995Z",
     "iopub.status.busy": "2025-09-30T10:05:48.814738Z",
     "iopub.status.idle": "2025-09-30T10:05:48.827482Z",
     "shell.execute_reply": "2025-09-30T10:05:48.826694Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.091189,
     "end_time": "2025-09-30T10:05:48.828837",
     "exception": false,
     "start_time": "2025-09-30T10:05:48.737648",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#--- RViT ---\n",
    "class RViT(nn.Module):\n",
    "    def __init__(self, yolo_channels=256, d_model=512, num_patches=1600, n_heads=8, num_encoder_layers=3, dim_feedforward=2048, dropout_rate=0.3):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.proj = nn.Sequential(\n",
    "            nn.Conv2d(yolo_channels, d_model, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(d_model),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout2d(dropout_rate if dropout_rate > 0 else 0)\n",
    "        )\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=d_model, nhead=n_heads, dim_feedforward=dim_feedforward,\n",
    "            dropout=dropout_rate, batch_first=True, norm_first=False\n",
    "        )\n",
    "        self.encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_encoder_layers)\n",
    "\n",
    "        self.pos_embed = nn.Parameter(torch.randn(1, num_patches + 1, d_model))\n",
    "        self.region_q = nn.Parameter(torch.zeros(1, 1, d_model))\n",
    "        \n",
    "        self.embed = nn.Embedding(NUM_CLASSES, d_model)\n",
    "        self.gru_num_layers = 1\n",
    "        self.gru = nn.GRU(d_model, d_model, num_layers=self.gru_num_layers, batch_first=True,\n",
    "                          dropout=dropout_rate if self.gru_num_layers > 1 else 0)\n",
    "        self.attn = MultiheadAttention(d_model, num_heads=n_heads, batch_first=True, dropout=dropout_rate)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Dropout(dropout_rate if dropout_rate > 0 else 0),\n",
    "            nn.Linear(2 * d_model, NUM_CLASSES)\n",
    "        )\n",
    "\n",
    "    def forward(self, fmap, target=None, teach_ratio=0.5, forced_output_length=None):\n",
    "        b = fmap.size(0)\n",
    "        x = self.proj(fmap)\n",
    "        x = x.flatten(2).permute(0, 2, 1)\n",
    "\n",
    "        current_num_patches = x.size(1)\n",
    "        expected_pos_embed_len = current_num_patches + 1\n",
    "        \n",
    "        if self.pos_embed.size(1) != expected_pos_embed_len:\n",
    "            if self.pos_embed.size(1) > expected_pos_embed_len:\n",
    "                pos_embed_to_add = self.pos_embed[:, :expected_pos_embed_len, :]\n",
    "            else:\n",
    "                raise ValueError(f\"RViT pos_embed second dim {self.pos_embed.size(1)} is smaller than required {expected_pos_embed_len}\")\n",
    "        else:\n",
    "            pos_embed_to_add = self.pos_embed\n",
    "\n",
    "        q = self.region_q.expand(b, -1, -1)\n",
    "        x = torch.cat([q, x], dim=1)\n",
    "        x = x + pos_embed_to_add\n",
    "\n",
    "        enc = self.encoder(x)\n",
    "        region_feat, spatial_feats = enc[:, 0], enc[:, 1:]\n",
    "        \n",
    "        if forced_output_length is not None:\n",
    "            max_gen_len = forced_output_length\n",
    "        elif target is not None:\n",
    "            max_gen_len = target.size(1) - 1\n",
    "        else:\n",
    "            max_gen_len = MAX_SEQ_LENGTH - 1\n",
    "\n",
    "        h = region_feat.unsqueeze(0).contiguous()\n",
    "        current_input_tokens = torch.full((b,), SOS_TOKEN, device=DEVICE, dtype=torch.long)\n",
    "        outputs_logits = []\n",
    "\n",
    "        finished_sequences_tracker = None\n",
    "        if target is None and forced_output_length is None:\n",
    "            finished_sequences_tracker = torch.zeros(b, dtype=torch.bool, device=DEVICE)\n",
    "            \n",
    "        for t in range(max_gen_len):\n",
    "            emb = self.embed(current_input_tokens).unsqueeze(1)\n",
    "            g, h = self.gru(emb, h)\n",
    "            a, _ = self.attn(g, spatial_feats, spatial_feats)\n",
    "            comb = torch.cat([g.squeeze(1), a.squeeze(1)], dim=-1)\n",
    "            logits_step = self.fc(comb)\n",
    "            outputs_logits.append(logits_step)\n",
    "\n",
    "            if target is not None and random.random() < teach_ratio:\n",
    "                next_input_candidate = target[:, t + 1]\n",
    "            else:\n",
    "                next_input_candidate = logits_step.argmax(-1)\n",
    "\n",
    "            if finished_sequences_tracker is not None:\n",
    "                eos_predicted_this_step = (next_input_candidate == EOS_TOKEN)\n",
    "                finished_sequences_tracker |= eos_predicted_this_step\n",
    "                current_input_tokens = torch.where(finished_sequences_tracker,\n",
    "                                                 torch.tensor(EOS_TOKEN, device=DEVICE, dtype=torch.long),\n",
    "                                                 next_input_candidate)\n",
    "                if finished_sequences_tracker.all():\n",
    "                    break\n",
    "            else:\n",
    "                current_input_tokens = next_input_candidate\n",
    "        \n",
    "        return torch.stack(outputs_logits, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "26f07ff3",
   "metadata": {
    "_cell_guid": "27d6d19d-92c2-48e4-bdf9-c1979871ed71",
    "_uuid": "8ae5c25d-6e89-4927-98c4-51ac2b3a0403",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-09-30T10:05:48.871149Z",
     "iopub.status.busy": "2025-09-30T10:05:48.870438Z",
     "iopub.status.idle": "2025-09-30T10:05:48.877201Z",
     "shell.execute_reply": "2025-09-30T10:05:48.876470Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.028632,
     "end_time": "2025-09-30T10:05:48.878320",
     "exception": false,
     "start_time": "2025-09-30T10:05:48.849688",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#--- YOLO_RViT ---\n",
    "class YOLO_RViT(nn.Module):\n",
    "    def __init__(self, yolo_path, yolo_target_feature_layer_idx=9):\n",
    "        super().__init__()\n",
    "        self.backbone = YoloBackbone(yolo_path, target_feature_layer_index=yolo_target_feature_layer_idx)\n",
    "        dummy_input = torch.randn(1, 3, 640, 640).to(DEVICE)\n",
    "        \n",
    "        original_backbone_training_mode = self.backbone.training\n",
    "        with torch.no_grad():\n",
    "            dummy_feats = self.backbone(dummy_input)\n",
    "        \n",
    "        yolo_channels = dummy_feats.shape[1]\n",
    "        h_feat, w_feat = dummy_feats.shape[2], dummy_feats.shape[3]\n",
    "        num_patches = h_feat * w_feat\n",
    "        \n",
    "        self.rvit = RViT(yolo_channels=yolo_channels, num_patches=num_patches).to(DEVICE)\n",
    "\n",
    "    def forward(self, x, target=None, teach_ratio=0.5, forced_output_length=None):\n",
    "        x = x.to(DEVICE)\n",
    "        feats = self.backbone(x)\n",
    "        return self.rvit(feats, target, teach_ratio, forced_output_length)\n",
    "\n",
    "    def train(self, mode: bool = True):\n",
    "        super().train(mode)\n",
    "        self.rvit.train(mode)\n",
    "        self.backbone.train(mode)\n",
    "        return self\n",
    "\n",
    "    def eval(self):\n",
    "        super().eval()\n",
    "        self.rvit.eval()\n",
    "        self.backbone.eval()\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "def339da",
   "metadata": {
    "_cell_guid": "a89a4749-903c-4199-9177-d794d1412095",
    "_uuid": "7d51a2f5-74da-42c5-bcab-9277d5410fa2",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-09-30T10:05:48.922041Z",
     "iopub.status.busy": "2025-09-30T10:05:48.921747Z",
     "iopub.status.idle": "2025-09-30T10:05:51.016993Z",
     "shell.execute_reply": "2025-09-30T10:05:51.016251Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 2.118676,
     "end_time": "2025-09-30T10:05:51.018362",
     "exception": false,
     "start_time": "2025-09-30T10:05:48.899686",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/albumentations/__init__.py:28: UserWarning: A new version of Albumentations is available: '2.0.8' (you have '2.0.4'). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
      "  check_for_updates()\n"
     ]
    }
   ],
   "source": [
    "import albumentations as A\n",
    "import cv2\n",
    "import random\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "IMG_SIZE = 640\n",
    "# Nếu dùng YOLO backbone -> False; nếu không thì True\n",
    "NORMALIZE_FOR_BACKBONE = False\n",
    "\n",
    "# Letterbox đặt CUỐI CÙNG để tránh lộ vùng đệm kỳ dị khi biến đổi hình học\n",
    "_LETTERBOX_LAST = [\n",
    "    A.LongestMaxSize(max_size=IMG_SIZE, interpolation=cv2.INTER_LINEAR, p=1.0),\n",
    "    A.PadIfNeeded(min_height=IMG_SIZE, min_width=IMG_SIZE,\n",
    "                  border_mode=cv2.BORDER_CONSTANT, fill=(114,114,114) , p=1.0),\n",
    "    A.ToFloat(max_value=255.0),  # <-- thêm dòng này\n",
    "]\n",
    "\n",
    "def _maybe_norm(normalize: bool):\n",
    "    return [A.Normalize(mean=(0.485,0.456,0.406), std=(0.229,0.224,0.225))] if normalize else []\n",
    "\n",
    "def make_ccpd_aug(subset: str, img_size=IMG_SIZE, normalize=False):\n",
    "    # ----- từng chủ đề/subnet -----\n",
    "    if subset == \"base\":\n",
    "        t = [\n",
    "            A.OneOf([\n",
    "                A.RandomBrightnessContrast(brightness_limit=0.15, contrast_limit=0.15),\n",
    "                A.ColorJitter(brightness=0.15, contrast=0.15, saturation=0.12, hue=0.03),\n",
    "            ], p=0.6),\n",
    "            A.GaussNoise(std_range=(0.005, 0.015), mean_range=(0.0,0.0), p=0.3),\n",
    "        ]\n",
    "    elif subset == \"db\":  # Dark & Bright\n",
    "        t = [\n",
    "            A.OneOf([\n",
    "                A.RandomBrightnessContrast(brightness_limit=0.45, contrast_limit=0.35),\n",
    "                A.RandomGamma(gamma_limit=(60,160)),\n",
    "            ], p=0.9),\n",
    "            A.OneOf([\n",
    "                A.RandomShadow(shadow_roi=(0.05,0.05,0.95,0.95),\n",
    "                               num_shadows_limit=(1,1),          # hoặc (1,2) nếu muốn ngẫu nhiên 1–2 bóng\n",
    "                               shadow_dimension=3,\n",
    "                               shadow_intensity_range=(0.25,0.5)),\n",
    "                A.RandomSunFlare(flare_roi=(0,0,1,0.8),\n",
    "                                 num_flare_circles_range=(2,5),\n",
    "                                 angle_range=(0.0,1.0),\n",
    "                                 src_radius=60),\n",
    "            ], p=0.35),\n",
    "        ]\n",
    "    elif subset == \"blur\":\n",
    "        t = [\n",
    "            A.OneOf([\n",
    "                A.MotionBlur(blur_limit=(5,11)),\n",
    "                A.GaussianBlur(blur_limit=(3,7)),\n",
    "                A.GlassBlur(sigma=0.7, max_delta=3, iterations=1),\n",
    "            ], p=0.9),\n",
    "        ]\n",
    "    elif subset == \"fn\":  # Far & Near\n",
    "        t = [\n",
    "            A.OneOf([\n",
    "                A.Affine(scale=(0.55,0.75), translate_percent=(0.0,0.02),\n",
    "                         rotate=(0,0), shear=(0,0),\n",
    "                         interpolation=cv2.INTER_LINEAR, mask_interpolation=cv2.INTER_NEAREST,\n",
    "                         border_mode=cv2.BORDER_CONSTANT, fill=(114,114,114)),\n",
    "                A.RandomResizedCrop(size=(img_size, img_size),\n",
    "                                    scale=(0.80,1.00), ratio=(0.95,1.05),\n",
    "                                    interpolation=cv2.INTER_LINEAR),\n",
    "            ], p=0.9),\n",
    "            A.OneOf([\n",
    "                A.Downscale(scale_range=(0.60,0.85)),\n",
    "                A.ImageCompression(quality_range=(40,70)),\n",
    "            ], p=0.5),\n",
    "        ]\n",
    "    elif subset == \"rotate\":\n",
    "        t = [\n",
    "            A.Affine(rotate=(-15,15), scale=(0.95,1.05), translate_percent=(0.0,0.04),\n",
    "                     shear=(0,0),\n",
    "                     interpolation=cv2.INTER_LINEAR, mask_interpolation=cv2.INTER_NEAREST,\n",
    "                     border_mode=cv2.BORDER_CONSTANT, fill=(114,114,114), p=1.0),\n",
    "        ]\n",
    "    elif subset == \"tilt\":\n",
    "        t = [\n",
    "            A.Affine(scale=(0.95,1.05), translate_percent=(0.0,0.05),\n",
    "                     rotate=(-3,3), shear=(-18,18),\n",
    "                     interpolation=cv2.INTER_LINEAR, mask_interpolation=cv2.INTER_NEAREST,\n",
    "                     border_mode=cv2.BORDER_CONSTANT, fill=(114,114,114), p=0.8),\n",
    "            A.Perspective(scale=(0.06,0.14), keep_size=True,\n",
    "                          border_mode=cv2.BORDER_CONSTANT, fill=(114,114,114),\n",
    "                          interpolation=cv2.INTER_LINEAR, mask_interpolation=cv2.INTER_NEAREST, p=0.5),\n",
    "        ]\n",
    "    elif subset == \"weather\":\n",
    "        t = [\n",
    "            A.OneOf([\n",
    "                A.RandomFog(fog_coef_range=(0.12,0.28), alpha_coef=0.06),\n",
    "                A.RandomRain(slant_range=(-10,10), drop_length=14, blur_value=3),\n",
    "                A.RandomSnow(snow_point_range=(0.10,0.30), brightness_coeff=1.5),\n",
    "            ], p=0.9),\n",
    "            A.ISONoise(color_shift=(0.01,0.05), intensity=(0.1,0.35), p=0.4),\n",
    "        ]\n",
    "    elif subset == \"challenge\":\n",
    "        t = [\n",
    "            A.OneOf([\n",
    "                A.Affine(scale=(0.90,1.08), translate_percent=(0.0,0.06),\n",
    "                         rotate=(-7,7), shear=(-15,15),\n",
    "                         interpolation=cv2.INTER_LINEAR, mask_interpolation=cv2.INTER_NEAREST,\n",
    "                         border_mode=cv2.BORDER_CONSTANT, fill=(114,114,114)),\n",
    "                A.Perspective(scale=(0.08,0.16), keep_size=True,\n",
    "                              border_mode=cv2.BORDER_CONSTANT, fill=(114,114,114),\n",
    "                              interpolation=cv2.INTER_LINEAR, mask_interpolation=cv2.INTER_NEAREST),\n",
    "            ], p=0.7),\n",
    "            A.OneOf([\n",
    "                A.RandomBrightnessContrast(brightness_limit=0.35, contrast_limit=0.3),\n",
    "                A.RandomGamma(gamma_limit=(70,140)),\n",
    "            ], p=0.8),\n",
    "            A.OneOf([\n",
    "                A.MotionBlur(blur_limit=(3,9)),\n",
    "                A.GaussianBlur(blur_limit=(3,7)),\n",
    "            ], p=0.5),\n",
    "            A.CoarseDropout(num_holes_range=(1,2),           # hoặc (1,3)\n",
    "                            hole_height_range=(0.06,0.12),\n",
    "                            hole_width_range=(0.06,0.12),\n",
    "                            fill=0, p=0.12),\n",
    "        ]\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown subset: {subset}\")\n",
    "\n",
    "    return A.Compose(\n",
    "        [*t, *_LETTERBOX_LAST, *_maybe_norm(normalize), ToTensorV2()],\n",
    "        strict=True\n",
    "    )\n",
    "\n",
    "\n",
    "class CCPDAugmenter:\n",
    "    def __init__(self, img_size=IMG_SIZE, normalize=False, weights=None, fixed_subset=None):\n",
    "        self.img_size = img_size\n",
    "        self.normalize = normalize\n",
    "        # phân phối gần giống “default test” của CCPD; bạn chỉnh tùy ý\n",
    "        self.weights = weights or {\n",
    "            \"base\": 0.01,\n",
    "            \"db\": 0.20,        # cao\n",
    "            \"fn\": 0.22,        # cao\n",
    "            \"rotate\": 0.14,    # tăng nhẹ\n",
    "            \"tilt\": 0.20,      # cao\n",
    "            \"weather\": 0.01,\n",
    "            \"challenge\": 0.22  # cao\n",
    "        }\n",
    "        self.fixed_subset = fixed_subset  # nếu muốn khóa 1 subnet\n",
    "\n",
    "    def _sample_subset(self):\n",
    "        if self.fixed_subset is not None:\n",
    "            return self.fixed_subset\n",
    "        names, probs = zip(*self.weights.items())\n",
    "        return random.choices(names, weights=probs, k=1)[0]\n",
    "\n",
    "    def __call__(self, image=None, **kwargs):\n",
    "        if image is None:\n",
    "            image = kwargs.get(\"image\")\n",
    "        subset = self._sample_subset()\n",
    "        tf = make_ccpd_aug(subset, img_size=self.img_size, normalize=self.normalize)\n",
    "        out = tf(image=image)\n",
    "        # có thể gắn kèm tên subnet để debug:\n",
    "        # out[\"subset\"] = subset\n",
    "        return out\n",
    "\n",
    "# === Drop-in thay thế cho train_tf / val_tf trong code của bạn ===\n",
    "train_tf = CCPDAugmenter(img_size=IMG_SIZE, normalize=NORMALIZE_FOR_BACKBONE)\n",
    "val_tf = A.Compose([*_LETTERBOX_LAST, *(_maybe_norm(NORMALIZE_FOR_BACKBONE)), ToTensorV2()],\n",
    "                   strict=True)\n",
    "class LicensePlateDataset(Dataset):\n",
    "    def __init__(self, img_dir, max_seq_length=15, is_train=True):\n",
    "        self.img_dir = img_dir\n",
    "        self.max_seq_length = max_seq_length\n",
    "        self.img_names = [f for f in os.listdir(self.img_dir)\n",
    "                          if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "        self.is_train = is_train\n",
    "        self.transform = train_tf if is_train else val_tf\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.img_names)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.img_names[idx]\n",
    "        # print(img_name)\n",
    "        \n",
    "        img_path = os.path.join(self.img_dir, img_name)\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "        # Albumentations nhận ndarray\n",
    "        img_np = np.array(img)\n",
    "        img_tensor = self.transform(image=img_np)[\"image\"]\n",
    "\n",
    "        # import matplotlib.pyplot as plt\n",
    "\n",
    "        # img_vis = img_tensor.detach().cpu().permute(1,2,0).numpy()  # (H,W,C)\n",
    "        # img_vis = np.clip(img_vis, 0, 1)\n",
    "        \n",
    "        # plt.imshow(img_vis)\n",
    "        # plt.axis('off')\n",
    "        # plt.show()\n",
    "\n",
    "        # Parse CCPD filename -> target (giữ logic của bạn)\n",
    "        license_text_field = img_name.split(\"-\")[-3]\n",
    "        chars = license_text_field.split(\"_\")\n",
    "        license_text = [\n",
    "            provinces[int(chars[0])],\n",
    "            alphabets[int(chars[1])],\n",
    "            ads[int(chars[2])],\n",
    "            ads[int(chars[3])],\n",
    "            ads[int(chars[4])],\n",
    "            ads[int(chars[5])],\n",
    "            ads[int(chars[6])]\n",
    "        ]\n",
    "        license_indices = char_to_indices(license_text)\n",
    "        target = torch.full((self.max_seq_length,), PAD_TOKEN, dtype=torch.long)\n",
    "        l = min(len(license_indices), self.max_seq_length)\n",
    "        target[:l] = torch.as_tensor(license_indices[:l], dtype=torch.long)\n",
    "\n",
    "        return img_tensor, target\n",
    "\n",
    "    @staticmethod\n",
    "    def collate_fn(batch):\n",
    "        images = torch.stack([item[0] for item in batch])\n",
    "        targets = torch.stack([item[1] for item in batch])\n",
    "        return images, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "96fe645e",
   "metadata": {
    "_cell_guid": "8237a1b9-4bbc-4b7b-8828-f2857b841a56",
    "_uuid": "8549d41b-3135-44e5-a977-8f2b4fff7213",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-09-30T10:05:51.062683Z",
     "iopub.status.busy": "2025-09-30T10:05:51.062246Z",
     "iopub.status.idle": "2025-09-30T10:05:51.065660Z",
     "shell.execute_reply": "2025-09-30T10:05:51.065067Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.026954,
     "end_time": "2025-09-30T10:05:51.066894",
     "exception": false,
     "start_time": "2025-09-30T10:05:51.039940",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# test = LicensePlateDataset(\"/kaggle/input/ccpd-preprocess/CCPD2019/ccpd_base\")\n",
    "# test.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7c92bf4e",
   "metadata": {
    "_cell_guid": "6ad7b7e0-e3e2-438a-977b-9dcbac02f57d",
    "_uuid": "46255100-474c-4caf-a6c2-b97f49673c2c",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-09-30T10:05:51.110494Z",
     "iopub.status.busy": "2025-09-30T10:05:51.110260Z",
     "iopub.status.idle": "2025-09-30T12:22:20.816778Z",
     "shell.execute_reply": "2025-09-30T12:22:20.815608Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 8189.729427,
     "end_time": "2025-09-30T12:22:20.818122",
     "exception": false,
     "start_time": "2025-09-30T10:05:51.088695",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test trên tập base: 100000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TEST]: 100%|██████████| 3125/3125 [1:19:44<00:00,  1.53s/it, loss=0.0991]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch | LR: 1.05e-09\n",
      "  Val Loss: 0.1017   | Val Acc (CRR): 0.9993\n",
      "  Val Exact Match Acc (E2E RR): 0.9955\n",
      "----------------------------------------------------------------------\n",
      "Test trên tập db: 10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TEST]: 100%|██████████| 313/313 [08:00<00:00,  1.53s/it, loss=0.244]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch | LR: 1.05e-09\n",
      "  Val Loss: 0.2765   | Val Acc (CRR): 0.9491\n",
      "  Val Exact Match Acc (E2E RR): 0.7359\n",
      "----------------------------------------------------------------------\n",
      "Test trên tập fn: 20000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TEST]: 100%|██████████| 625/625 [15:59<00:00,  1.54s/it, loss=0.557]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch | LR: 1.05e-09\n",
      "  Val Loss: 0.4373   | Val Acc (CRR): 0.8972\n",
      "  Val Exact Match Acc (E2E RR): 0.6069\n",
      "----------------------------------------------------------------------\n",
      "Test trên tập rotate: 10053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TEST]: 100%|██████████| 315/315 [08:04<00:00,  1.54s/it, loss=0.173]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch | LR: 1.05e-09\n",
      "  Val Loss: 0.1801   | Val Acc (CRR): 0.9759\n",
      "  Val Exact Match Acc (E2E RR): 0.8768\n",
      "----------------------------------------------------------------------\n",
      "Test trên tập weather: 9999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TEST]: 100%|██████████| 313/313 [08:07<00:00,  1.56s/it, loss=0.101]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch | LR: 1.05e-09\n",
      "  Val Loss: 0.1115   | Val Acc (CRR): 0.9968\n",
      "  Val Exact Match Acc (E2E RR): 0.9803\n",
      "----------------------------------------------------------------------\n",
      "Test trên tập challenge: 10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TEST]: 100%|██████████| 313/313 [08:11<00:00,  1.57s/it, loss=0.457]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch | LR: 1.05e-09\n",
      "  Val Loss: 0.3839   | Val Acc (CRR): 0.9171\n",
      "  Val Exact Match Acc (E2E RR): 0.6367\n",
      "----------------------------------------------------------------------\n",
      "Test trên tập tilt: 10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TEST]: 100%|██████████| 313/313 [08:01<00:00,  1.54s/it, loss=0.218]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch | LR: 1.05e-09\n",
      "  Val Loss: 0.2536   | Val Acc (CRR): 0.9547\n",
      "  Val Exact Match Acc (E2E RR): 0.7790\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Training completed!\n",
      "Final val accuracy (Greedy Character Level): 0.9547\n",
      "Final val accuracy (Constrained Length Exact Match): 0.7790\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#--- Training ---\n",
    "YOLO_MODEL_PATH = '/kaggle/input/m/thitenguyen/yolov11s/pytorch/default/1/best.pt'\n",
    "YOLO_TARGET_FEATURE_LAYER_INDEX = 13\n",
    "\n",
    "IMG_DIR_TRAIN = \"/kaggle/input/ccpd-base-dataset/ccpd_base_dataset/images/train\"\n",
    "LICENSE_DIR_TRAIN = \"/kaggle/input/dataset-lpr-test/License_plate_data2/text/train\"\n",
    "IMG_DIR_VAL = \"/kaggle/input/ccpd-base-dataset/ccpd_base_dataset/images/val\"\n",
    "LICENSE_DIR_VAL = \"/kaggle/input/dataset-lpr-test/License_plate_data2/text/val\"\n",
    "\n",
    "MAX_SEQ_LENGTH = 15\n",
    "BATCH_SIZE = 32\n",
    "NUM_WORKERS = 4\n",
    "LEARNING_RATE = 1e-5\n",
    "MAX_LR_SCHEDULER = 5e-4\n",
    "WEIGHT_DECAY = 5e-5\n",
    "NUM_EPOCHS = 4\n",
    "ACCUM_STEPS = 2\n",
    "PATIENCE_EARLY_STOP = 100\n",
    "TEACH_RATIO_START = 0.7\n",
    "TEACH_RATIO_END = 0.05\n",
    "LABEL_SMOOTHING = 0.01\n",
    "\n",
    "scaler = torch.amp.GradScaler(DEVICE)\n",
    "autocast_context = lambda: torch.amp.autocast(DEVICE)\n",
    "\n",
    "\n",
    "model = YOLO_RViT(YOLO_MODEL_PATH, yolo_target_feature_layer_idx=YOLO_TARGET_FEATURE_LAYER_INDEX).to(DEVICE)\n",
    "\n",
    "optimizer = torch.optim.AdamW(\n",
    "    model.parameters(),\n",
    "    lr=LEARNING_RATE,\n",
    "    weight_decay=WEIGHT_DECAY\n",
    ")\n",
    "\n",
    "scheduler_type = \"OneCycleLR\"\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss(ignore_index=PAD_TOKEN, label_smoothing=LABEL_SMOOTHING)\n",
    "early_stopper = EarlyStopping(patience=PATIENCE_EARLY_STOP, min_delta=0.0005, monitor_metric='val_acc', mode='max', verbose=True)\n",
    "\n",
    "checkpoint = torch.load(\"/kaggle/input/ccpd_base_good/pytorch/default/1/CCPD_BASE_GOOD.pth\", map_location=DEVICE, weights_only=True)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "\n",
    "train_loss_values, val_loss_values = [], []\n",
    "train_acc_values, val_acc_values, val_acc_constrained_values = [], [], []\n",
    "epoch_count_list = []\n",
    "best_val_acc = 0.0\n",
    "\n",
    "TEST_FOLDERS = {\n",
    "    \"base\": \"/kaggle/input/ccpd-preprocess/CCPD2019/ccpd_base\", \n",
    "    \"db\":        \"/kaggle/input/ccpd-preprocess/CCPD2019/ccpd_db\",\n",
    "    \"fn\":        \"/kaggle/input/ccpd-preprocess/CCPD2019/ccpd_fn\",\n",
    "    \"rotate\":    \"/kaggle/input/ccpd-preprocess/CCPD2019/ccpd_rotate\",\n",
    "    \"weather\":   \"/kaggle/input/ccpd-preprocess/CCPD2019/ccpd_weather\",\n",
    "    \"challenge\": \"/kaggle/input/ccpd-preprocess/CCPD2019/ccpd_challenge\",\n",
    "    \"tilt\": \"/kaggle/input/ccpd-preprocess/CCPD2019/ccpd_tilt\",\n",
    "}\n",
    "\n",
    "for name, path in TEST_FOLDERS.items():\n",
    "    test_dataset = LicensePlateDataset(img_dir=path, max_seq_length=MAX_SEQ_LENGTH, is_train=False)\n",
    "    if name == \"challenge\":\n",
    "        test_dataset = Subset(test_dataset, torch.randperm(len(test_dataset)).tolist()[:10000])\n",
    "    elif name == \"fn\":\n",
    "        test_dataset = Subset(test_dataset, torch.randperm(len(test_dataset)).tolist()[:20000])\n",
    "    elif name == \"tilt\":\n",
    "        test_dataset = Subset(test_dataset, torch.randperm(len(test_dataset)).tolist()[:10000])\n",
    "    elif name == \"base\":\n",
    "        test_dataset = Subset(test_dataset, torch.randperm(len(test_dataset)).tolist()[:100000])\n",
    "    elif name == \"db\":\n",
    "        test_dataset = Subset(test_dataset, torch.randperm(len(test_dataset)).tolist()[:10000])\n",
    "    \n",
    "    test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, collate_fn=LicensePlateDataset.collate_fn, pin_memory=(DEVICE == 'cuda'))\n",
    "    print(f\"Test trên tập {name}: {len(test_dataset)}\")\n",
    "\n",
    "    # --- Validation Loop ---\n",
    "    model.eval()\n",
    "    val_loss, val_correct, val_total_chars, val_correct_constrained, val_total_sequences_constrained = 0, 0, 0, 0, 0\n",
    "    pbar_val = tqdm(test_dataloader, desc=f\"[TEST]\")\n",
    "    with torch.no_grad():\n",
    "        for imgs, targets in pbar_val:\n",
    "            imgs, targets = imgs.to(DEVICE, non_blocking=True), targets.to(DEVICE, non_blocking=True)\n",
    "            \n",
    "            with autocast_context():\n",
    "                outputs = model(imgs, target=None, teach_ratio=0.0)\n",
    "                out_seq_len_val = outputs.size(1)\n",
    "                tgt_content_len_val = targets.size(1) - 1\n",
    "                if out_seq_len_val > tgt_content_len_val:\n",
    "                    outputs_for_loss_val = outputs[:, :tgt_content_len_val, :]\n",
    "                elif out_seq_len_val < tgt_content_len_val:\n",
    "                    padding_val_val = torch.zeros(outputs.size(0), tgt_content_len_val - out_seq_len_val, NUM_CLASSES, device=DEVICE)\n",
    "                    padding_val_val[:,:,PAD_TOKEN] = 1\n",
    "                    outputs_for_loss_val = torch.cat([outputs, padding_val_val], dim=1)\n",
    "                else:\n",
    "                    outputs_for_loss_val = outputs\n",
    "                flat_outputs_val = outputs_for_loss_val.reshape(-1, NUM_CLASSES)\n",
    "                flat_targets_val = targets[:, 1:].reshape(-1)\n",
    "                loss = loss_fn(flat_outputs_val, flat_targets_val)\n",
    "            \n",
    "            val_loss += loss.item()\n",
    "            preds_val = outputs_for_loss_val.argmax(-1)\n",
    "            true_chars_val = targets[:, 1:]\n",
    "            for i in range(imgs.size(0)):\n",
    "                pred_seq_val_list = preds_val[i].tolist()\n",
    "                if EOS_TOKEN in pred_seq_val_list:\n",
    "                    pred_seq_val_list = pred_seq_val_list[:pred_seq_val_list.index(EOS_TOKEN)]\n",
    "                \n",
    "                true_seq_val_list = true_chars_val[i].tolist()\n",
    "                true_content_val = [x for x in true_seq_val_list if x not in [EOS_TOKEN, PAD_TOKEN]]\n",
    "                len_true_content_val = len(true_content_val)\n",
    "\n",
    "                cmp_len_val = min(len(pred_seq_val_list), len_true_content_val)\n",
    "                if cmp_len_val > 0:\n",
    "                    val_correct += (torch.tensor(pred_seq_val_list[:cmp_len_val]) == torch.tensor(true_content_val[:cmp_len_val])).sum().item()\n",
    "                val_total_chars += len_true_content_val\n",
    "\n",
    "                if len_true_content_val > 0:\n",
    "                    with autocast_context():\n",
    "                        outputs_constrained_sample = model(imgs[i:i+1], target=None, teach_ratio=0.0, forced_output_length=len_true_content_val)\n",
    "                    preds_constrained_sample = outputs_constrained_sample.argmax(-1).squeeze(0).tolist()\n",
    "                    final_preds_constrained = []\n",
    "                    for tk_id in preds_constrained_sample:\n",
    "                        if tk_id == EOS_TOKEN:\n",
    "                            break\n",
    "                        final_preds_constrained.append(tk_id)\n",
    "                    if final_preds_constrained == true_content_val:\n",
    "                        val_correct_constrained += 1\n",
    "                val_total_sequences_constrained += 1\n",
    "            \n",
    "            pbar_val.set_postfix(loss=loss.item())\n",
    "\n",
    "    avg_val_loss = val_loss / len(test_dataloader) if len(test_dataloader) > 0 else 0\n",
    "    avg_val_acc = val_correct / val_total_chars if val_total_chars > 0 else 0\n",
    "    avg_val_acc_constrained = val_correct_constrained / val_total_sequences_constrained if val_total_sequences_constrained > 0 else 0\n",
    "\n",
    "    \n",
    "    val_loss_values.append(avg_val_loss)\n",
    "    val_acc_values.append(avg_val_acc)\n",
    "    val_acc_constrained_values.append(avg_val_acc_constrained)\n",
    "    \n",
    "    \n",
    "    print(f\"\\nEpoch | LR: {optimizer.param_groups[0]['lr']:.2e}\")\n",
    "    print(f\"  Val Loss: {avg_val_loss:.4f}   | Val Acc (CRR): {avg_val_acc:.4f}\")\n",
    "    print(f\"  Val Exact Match Acc (E2E RR): {avg_val_acc_constrained:.4f}\")\n",
    "    print(\"-\" * 70)\n",
    "\n",
    "print(\"\\nTraining completed!\")\n",
    "if val_acc_values:\n",
    "    print(f\"Final val accuracy (Greedy Character Level): {val_acc_values[-1]:.4f}\")\n",
    "if val_acc_constrained_values:\n",
    "    print(f\"Final val accuracy (Constrained Length Exact Match): {val_acc_constrained_values[-1]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9abc9953",
   "metadata": {
    "_cell_guid": "85d48be9-48c5-464f-911a-4b04a200d4f4",
    "_uuid": "0ada5dda-edfb-47c5-8820-19e2f0c07284",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-09-30T12:22:21.804364Z",
     "iopub.status.busy": "2025-09-30T12:22:21.804057Z",
     "iopub.status.idle": "2025-09-30T12:22:22.130987Z",
     "shell.execute_reply": "2025-09-30T12:22:22.130028Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.775941,
     "end_time": "2025-09-30T12:22:22.132075",
     "exception": true,
     "start_time": "2025-09-30T12:22:21.356134",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension, but have shapes (0,) and (7,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_19/2142604146.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch_count_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loss_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Train Loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmarker\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'o'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinestyle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'-'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch_count_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loss_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Validation Loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmarker\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m's'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinestyle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'--'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loss Curves'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Epochs'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2810\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0m_copy_docstring_and_deprecators\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2811\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscalex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaley\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2812\u001b[0;31m     return gca().plot(\n\u001b[0m\u001b[1;32m   2813\u001b[0m         \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscalex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscalex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaley\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscaley\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2814\u001b[0m         **({\"data\": data} if data is not None else {}), **kwargs)\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1686\u001b[0m         \"\"\"\n\u001b[1;32m   1687\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLine2D\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1688\u001b[0;31m         \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1689\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1690\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 311\u001b[0;31m             yield from self._plot_args(\n\u001b[0m\u001b[1;32m    312\u001b[0m                 this, kwargs, ambiguous_fmt_datakey=ambiguous_fmt_datakey)\n\u001b[1;32m    313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[0;34m(self, tup, kwargs, return_kwargs, ambiguous_fmt_datakey)\u001b[0m\n\u001b[1;32m    502\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m             raise ValueError(f\"x and y must have same first dimension, but \"\n\u001b[0m\u001b[1;32m    505\u001b[0m                              f\"have shapes {x.shape} and {y.shape}\")\n\u001b[1;32m    506\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (0,) and (7,)"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1800x1200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting\n",
    "plt.figure(figsize=(18, 12))\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.plot(epoch_count_list, train_loss_values, label='Train Loss', marker='o', linestyle='-')\n",
    "plt.plot(epoch_count_list, val_loss_values, label='Validation Loss', marker='s', linestyle='--')\n",
    "plt.title('Loss Curves')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.plot(epoch_count_list, train_acc_values, label='Train Char Accuracy', marker='o', linestyle='-')\n",
    "plt.plot(epoch_count_list, val_acc_values, label='Validation Char Accuracy (Greedy)', marker='s', linestyle='--')\n",
    "plt.title('Character Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Character Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"performance_plots.png\")\n",
    "plt.show()\n",
    "print(\"Saved plots to performance_plots.png\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 4072694,
     "sourceId": 7073289,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7283240,
     "sourceId": 11903981,
     "sourceType": "datasetVersion"
    },
    {
     "modelId": 357248,
     "modelInstanceId": 336244,
     "sourceId": 411841,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelId": 357250,
     "modelInstanceId": 336246,
     "sourceId": 411843,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelId": 357253,
     "modelInstanceId": 336249,
     "sourceId": 411846,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelId": 372818,
     "modelInstanceId": 351568,
     "sourceId": 431310,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelId": 414365,
     "modelInstanceId": 395828,
     "sourceId": 498166,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelId": 414998,
     "modelInstanceId": 396516,
     "sourceId": 499167,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelId": 418402,
     "modelInstanceId": 400131,
     "sourceId": 503719,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelId": 419075,
     "modelInstanceId": 400915,
     "sourceId": 504853,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelId": 430419,
     "modelInstanceId": 412657,
     "sourceId": 527025,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelId": 432054,
     "modelInstanceId": 414305,
     "sourceId": 529632,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelId": 435907,
     "modelInstanceId": 418241,
     "sourceId": 543424,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelId": 436426,
     "modelInstanceId": 418774,
     "sourceId": 545580,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 461074,
     "modelInstanceId": 444586,
     "sourceId": 594029,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 31011,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 8301.94796,
   "end_time": "2025-09-30T12:22:25.761504",
   "environment_variables": {},
   "exception": true,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-09-30T10:04:03.813544",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
