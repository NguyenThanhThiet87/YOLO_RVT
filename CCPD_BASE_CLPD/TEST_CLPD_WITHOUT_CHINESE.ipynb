{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25514f51",
   "metadata": {
    "_cell_guid": "a4f6b7c3-5616-42fc-9581-bfeea0906d94",
    "_uuid": "2e3b0657-326f-4ea8-97f2-eed699c0a1f2",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-09-30T08:05:43.927457Z",
     "iopub.status.busy": "2025-09-30T08:05:43.927227Z",
     "iopub.status.idle": "2025-09-30T08:07:11.426582Z",
     "shell.execute_reply": "2025-09-30T08:07:11.425834Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 87.504819,
     "end_time": "2025-09-30T08:07:11.428148",
     "exception": false,
     "start_time": "2025-09-30T08:05:43.923329",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ultralytics\r\n",
      "  Downloading ultralytics-8.3.203-py3-none-any.whl.metadata (37 kB)\r\n",
      "Collecting torchtoolbox\r\n",
      "  Downloading torchtoolbox-0.1.8.2-py3-none-any.whl.metadata (15 kB)\r\n",
      "Collecting bitsandbytes\r\n",
      "  Downloading bitsandbytes-0.47.0-py3-none-manylinux_2_24_x86_64.whl.metadata (11 kB)\r\n",
      "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.26.4)\r\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (3.7.2)\r\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.11.0.86)\r\n",
      "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (11.2.1)\r\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (6.0.2)\r\n",
      "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.32.4)\r\n",
      "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.15.3)\r\n",
      "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.6.0+cu124)\r\n",
      "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.21.0+cu124)\r\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ultralytics) (7.0.0)\r\n",
      "Requirement already satisfied: polars in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.21.0)\r\n",
      "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\r\n",
      "  Downloading ultralytics_thop-2.0.17-py3-none-any.whl.metadata (14 kB)\r\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torchtoolbox) (4.67.1)\r\n",
      "Requirement already satisfied: pyarrow in /usr/local/lib/python3.11/dist-packages (from torchtoolbox) (19.0.1)\r\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from torchtoolbox) (1.17.0)\r\n",
      "Collecting lmdb (from torchtoolbox)\r\n",
      "  Downloading lmdb-1.7.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.3 kB)\r\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from torchtoolbox) (1.2.2)\r\n",
      "Requirement already satisfied: tensorboard in /usr/local/lib/python3.11/dist-packages (from torchtoolbox) (2.18.0)\r\n",
      "Requirement already satisfied: prettytable in /usr/local/lib/python3.11/dist-packages (from torchtoolbox) (3.16.0)\r\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (from torchtoolbox) (4.52.4)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.2)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.58.4)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.8)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (25.0)\r\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.0.9)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.0->ultralytics) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.0->ultralytics) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.0->ultralytics) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.0->ultralytics) (2025.2.0)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.0->ultralytics) (2022.2.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.0->ultralytics) (2.4.1)\r\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.4.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2.5.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2025.6.15)\r\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.18.0)\r\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (4.14.0)\r\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.5)\r\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\r\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2025.5.1)\r\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\r\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\r\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\r\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.8.0->ultralytics)\r\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.8.0->ultralytics)\r\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.8.0->ultralytics)\r\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.8.0->ultralytics)\r\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.8.0->ultralytics)\r\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.8.0->ultralytics)\r\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\r\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (0.6.2)\r\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2.21.5)\r\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\r\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\r\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.2.0)\r\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\r\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prettytable->torchtoolbox) (0.2.13)\r\n",
      "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->torchtoolbox) (1.5.1)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->torchtoolbox) (3.6.0)\r\n",
      "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.11/dist-packages (from tensorboard->torchtoolbox) (1.4.0)\r\n",
      "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.11/dist-packages (from tensorboard->torchtoolbox) (1.73.1)\r\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard->torchtoolbox) (3.8.2)\r\n",
      "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.11/dist-packages (from tensorboard->torchtoolbox) (3.20.3)\r\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard->torchtoolbox) (75.2.0)\r\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard->torchtoolbox) (0.7.2)\r\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard->torchtoolbox) (3.1.3)\r\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers->torchtoolbox) (0.33.1)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers->torchtoolbox) (2024.11.6)\r\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers->torchtoolbox) (0.21.2)\r\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers->torchtoolbox) (0.5.3)\r\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers->torchtoolbox) (1.1.5)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard->torchtoolbox) (3.0.2)\r\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.23.0->ultralytics) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.23.0->ultralytics) (2022.2.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.23.0->ultralytics) (1.4.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.23.0->ultralytics) (2024.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.23.0->ultralytics) (2024.2.0)\r\n",
      "Downloading ultralytics-8.3.203-py3-none-any.whl (1.1 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading torchtoolbox-0.1.8.2-py3-none-any.whl (84 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.0/85.0 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading bitsandbytes-0.47.0-py3-none-manylinux_2_24_x86_64.whl (61.3 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.3/61.3 MB\u001b[0m \u001b[31m27.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m95.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m80.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m42.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m31.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m82.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading ultralytics_thop-2.0.17-py3-none-any.whl (28 kB)\r\n",
      "Downloading lmdb-1.7.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (299 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m299.6/299.6 kB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: lmdb, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, ultralytics-thop, ultralytics, torchtoolbox, bitsandbytes\r\n",
      "  Attempting uninstall: nvidia-nvjitlink-cu12\r\n",
      "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\r\n",
      "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\r\n",
      "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\r\n",
      "  Attempting uninstall: nvidia-curand-cu12\r\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.6.82\r\n",
      "    Uninstalling nvidia-curand-cu12-10.3.6.82:\r\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\r\n",
      "  Attempting uninstall: nvidia-cufft-cu12\r\n",
      "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\r\n",
      "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\r\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\r\n",
      "  Attempting uninstall: nvidia-cuda-runtime-cu12\r\n",
      "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\r\n",
      "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\r\n",
      "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\r\n",
      "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\r\n",
      "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\r\n",
      "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\r\n",
      "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\r\n",
      "  Attempting uninstall: nvidia-cuda-cupti-cu12\r\n",
      "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\r\n",
      "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\r\n",
      "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\r\n",
      "  Attempting uninstall: nvidia-cublas-cu12\r\n",
      "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\r\n",
      "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\r\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\r\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\r\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\r\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\r\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\r\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\r\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\r\n",
      "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\r\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\r\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\r\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\r\n",
      "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\r\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\r\n",
      "Successfully installed bitsandbytes-0.47.0 lmdb-1.7.3 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 torchtoolbox-0.1.8.2 ultralytics-8.3.203 ultralytics-thop-2.0.17\r\n"
     ]
    }
   ],
   "source": [
    "!pip install ultralytics torchtoolbox bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21511f15",
   "metadata": {
    "_cell_guid": "a0cd904b-04d5-4548-b094-4eec0cfcca21",
    "_uuid": "6d1342d2-12b0-455f-8efe-e076ba232b0c",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-09-30T08:07:11.475364Z",
     "iopub.status.busy": "2025-09-30T08:07:11.475104Z",
     "iopub.status.idle": "2025-09-30T08:07:55.700527Z",
     "shell.execute_reply": "2025-09-30T08:07:55.699505Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 44.250899,
     "end_time": "2025-09-30T08:07:55.701940",
     "exception": false,
     "start_time": "2025-09-30T08:07:11.451041",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new Ultralytics Settings v0.0.6 file ✅ \n",
      "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
      "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(\n",
      "Epoch 1/1 [VAL]: 100%|██████████| 150/150 [00:22<00:00,  6.73it/s, loss=0.685]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/1 | LR: 1.05e-09 | Teach: 0.70 | Scheduler: OneCycleLR\n",
      "  Val Loss: 1.0455   | Val Acc Ký tự: 0.9075\n",
      "  Test Acc Khớp chính xác (Toàn bộ chuỗi): 0.8083\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Quá trình huấn luyện đã hoàn thành!\n",
      "Độ chính xác kiểm tra cuối cùng (Cấp độ ký tự): 0.9075\n",
      "Độ chính xác khớp chính xác cuối cùng: 0.8083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from ultralytics import YOLO\n",
    "from torch.nn import MultiheadAttention\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import random\n",
    "import os\n",
    "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'\n",
    "from torch.utils.data import Dataset, DataLoader, Sampler, Subset, SubsetRandomSampler\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from torchtoolbox.tools import mixup_data, mixup_criterion\n",
    "import bitsandbytes.optim as bnb_optim\n",
    "\n",
    "# Đảm bảo tính lặp lại của kết quả\n",
    "torch.manual_seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(42)\n",
    "\n",
    "CHINESE_COUNT = 34  # 34 ký tự Chinese đứng đầu trong CHARACTERS\n",
    "def is_chinese_idx(idx: int) -> bool:\n",
    "    return 0 <= idx < CHINESE_COUNT\n",
    "\n",
    "#--- Các hằng số ---\n",
    "provinces = [\"皖\", \"沪\", \"津\", \"渝\", \"冀\", \"晋\", \"蒙\", \"辽\", \"吉\", \"黑\", \"苏\", \"浙\", \"京\", \"闽\", \"赣\", \"鲁\", \"豫\", \"鄂\", \"湘\", \"粤\", \"桂\", \"琼\", \"川\", \"贵\", \"云\", \"藏\", \"陕\", \"甘\", \"青\", \"宁\", \"新\", \"警\", \"学\", \"O\"]\n",
    "alphabets = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'J', 'K', 'L', 'M', 'N', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W',\n",
    "             'X', 'Y', 'Z', 'O']\n",
    "ads = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'J', 'K', 'L', 'M', 'N', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X',\n",
    "       'Y', 'Z', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'O']\n",
    "\n",
    "CHARACTERS = [\n",
    "    \"皖\",\"沪\",\"津\",\"渝\",\"冀\",\"晋\",\"蒙\",\"辽\",\"吉\",\"黑\",\"苏\",\"浙\",\"京\",\"闽\",\"赣\",\"鲁\",\"豫\",\"鄂\",\"湘\",\"粤\",\"桂\",\"琼\",\"川\",\"贵\",\"云\",\"藏\",\"陕\",\"甘\",\"青\",\"宁\",\"新\",\"警\",\"学\",\"O\",\n",
    "    \"A\",\"B\",\"C\",\"D\",\"E\",\"F\",\"G\",\"H\",\"J\",\"K\",\"L\",\"M\",\"N\",\"P\",\"Q\",\"R\",\"S\",\"T\",\"U\",\"V\",\"W\",\"X\",\"Y\",\"Z\",\n",
    "    \"0\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\"]\n",
    "\n",
    "SOS_TOKEN = len(CHARACTERS)  # Mã thông báo bắt đầu chuỗi\n",
    "EOS_TOKEN = len(CHARACTERS) + 1  # Mã thông báo kết thúc chuỗi\n",
    "PAD_TOKEN = len(CHARACTERS) + 2  # Mã thông báo đệm\n",
    "NUM_CLASSES = len(CHARACTERS) + 3  # Bao gồm SOS, EOS, PAD\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "#--- Các hàm tiện ích ---\n",
    "def index_to_char(indices, include_special_tokens=False):\n",
    "    result = []\n",
    "    for i in indices:\n",
    "        i = i.item() if torch.is_tensor(i) else i\n",
    "        if i == SOS_TOKEN:\n",
    "            if include_special_tokens: result.append('[SOS]')\n",
    "        elif i == EOS_TOKEN:\n",
    "            if include_special_tokens: result.append('[EOS]')\n",
    "            break\n",
    "        elif 0 <= i < len(CHARACTERS):\n",
    "            result.append(CHARACTERS[i])\n",
    "        else:\n",
    "            if include_special_tokens or i not in [SOS_TOKEN, EOS_TOKEN, PAD_TOKEN]:\n",
    "                result.append(f'[UNK_{i}]')\n",
    "    return ''.join(result)\n",
    "\n",
    "def char_to_indices(text):\n",
    "    indices = [SOS_TOKEN]\n",
    "    for c in text:\n",
    "        if c in CHARACTERS:\n",
    "            indices.append(CHARACTERS.index(c))\n",
    "    indices.append(EOS_TOKEN)\n",
    "    return torch.tensor(indices, dtype=torch.long)\n",
    "\n",
    "#--- Lớp bao bọc YOLO với RViT ---\n",
    "class YoloBackbone(nn.Module):\n",
    "    def __init__(self, model_path, target_feature_layer_idx=9):\n",
    "        super().__init__()\n",
    "        _temp_yolo_instance = YOLO(model_path)\n",
    "        self.yolo_detection_model = _temp_yolo_instance.model\n",
    "        self.yolo_detection_model.to(DEVICE)\n",
    "        self.target_feature_layer_index = target_feature_layer_idx\n",
    "\n",
    "        for name, param in self.yolo_detection_model.named_parameters():\n",
    "            param.requires_grad = True\n",
    "        \n",
    "        self._hook_handle = None\n",
    "        self._fmap_out_hook = []\n",
    "        \n",
    "        self._register_hook()\n",
    "\n",
    "    def _hook_fn_extractor(self, module, input_val, output_val):\n",
    "        if isinstance(output_val, torch.Tensor):\n",
    "            self._fmap_out_hook.append(output_val)\n",
    "        elif isinstance(output_val, (list, tuple)):\n",
    "            for item in output_val:\n",
    "                if isinstance(item, torch.Tensor):\n",
    "                    self._fmap_out_hook.append(item)\n",
    "                    break\n",
    "\n",
    "    def _register_hook(self):\n",
    "        # Gắn hook vào lớp mục tiêu của mạng YOLO để trích xuất các đặc trưng.\n",
    "        layer_to_hook = self.yolo_detection_model.model[self.target_feature_layer_index]\n",
    "        self._hook_handle = layer_to_hook.register_forward_hook(self._hook_fn_extractor)\n",
    "\n",
    "    def _remove_hook(self):\n",
    "        if self._hook_handle:\n",
    "            self._hook_handle.remove()\n",
    "            self._hook_handle = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        self._fmap_out_hook.clear()\n",
    "        _ = self.yolo_detection_model(x)\n",
    "        out_tensor = self._fmap_out_hook[0]\n",
    "        return out_tensor if out_tensor.dim() == 4 else out_tensor.unsqueeze(0)\n",
    "\n",
    "#--- RViT đơn giản hóa ---\n",
    "class RViT(nn.Module):\n",
    "    def __init__(self, yolo_channels=256, d_model=512, num_patches=1600, n_heads=8, num_encoder_layers=3, dim_feedforward=2048, dropout_rate=0.5):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.proj = nn.Sequential(\n",
    "            nn.Conv2d(yolo_channels, d_model, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(d_model),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout2d(dropout_rate if dropout_rate > 0 else 0)\n",
    "        )\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=d_model, nhead=n_heads, dim_feedforward=dim_feedforward,\n",
    "            dropout=dropout_rate, batch_first=True, norm_first=True\n",
    "        )\n",
    "        self.encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_encoder_layers)\n",
    "        self.pos_embed = nn.Parameter(torch.randn(1, num_patches + 1, d_model))\n",
    "        self.region_q = nn.Parameter(torch.zeros(1, 1, d_model))\n",
    "        self.embed = nn.Embedding(NUM_CLASSES, d_model)\n",
    "        self.gru_num_layers = 1\n",
    "        self.gru = nn.GRU(d_model, d_model, num_layers=self.gru_num_layers, batch_first=True,\n",
    "                          dropout=dropout_rate if self.gru_num_layers > 1 else 0)\n",
    "        self.attn = MultiheadAttention(d_model, num_heads=n_heads, batch_first=True, dropout=dropout_rate)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Dropout(dropout_rate if dropout_rate > 0 else 0),\n",
    "            nn.Linear(2 * d_model, NUM_CLASSES)\n",
    "        )\n",
    "\n",
    "    def forward(self, fmap, target=None, teach_ratio=0.5, forced_output_length=None):\n",
    "        b = fmap.size(0)\n",
    "        x = self.proj(fmap)\n",
    "        x = x.flatten(2).permute(0, 2, 1)\n",
    "\n",
    "        current_num_patches = x.size(1)\n",
    "        expected_pos_embed_len = current_num_patches + 1\n",
    "        \n",
    "        if self.pos_embed.size(1) != expected_pos_embed_len:\n",
    "            if self.pos_embed.size(1) > expected_pos_embed_len:\n",
    "                pos_embed_to_add = self.pos_embed[:, :expected_pos_embed_len, :]\n",
    "            else:\n",
    "                raise ValueError(f\"RViT pos_embed second dim {self.pos_embed.size(1)} is smaller than required {expected_pos_embed_len}\")\n",
    "        else:\n",
    "            pos_embed_to_add = self.pos_embed\n",
    "\n",
    "        q = self.region_q.expand(b, -1, -1)\n",
    "        x = torch.cat([q, x], dim=1)\n",
    "        x = x + pos_embed_to_add\n",
    "\n",
    "        enc = self.encoder(x)\n",
    "        region_feat, spatial_feats = enc[:, 0], enc[:, 1:]\n",
    "        \n",
    "        if forced_output_length is not None:\n",
    "            max_gen_len = forced_output_length\n",
    "        elif target is not None:\n",
    "            max_gen_len = target.size(1) - 1\n",
    "        else:\n",
    "            max_gen_len = MAX_SEQ_LENGTH - 1\n",
    "\n",
    "        h = region_feat.unsqueeze(0).contiguous()\n",
    "        current_input_tokens = torch.full((b,), SOS_TOKEN, device=DEVICE, dtype=torch.long)\n",
    "        outputs_logits = []\n",
    "\n",
    "        finished_sequences_tracker = None\n",
    "        if target is None:\n",
    "            finished_sequences_tracker = torch.zeros(b, dtype=torch.bool, device=DEVICE)\n",
    "\n",
    "        for t in range(max_gen_len):\n",
    "            emb = self.embed(current_input_tokens).unsqueeze(1)\n",
    "            g, h = self.gru(emb, h)\n",
    "            a, _ = self.attn(g, spatial_feats, spatial_feats)\n",
    "            comb = torch.cat([g.squeeze(1), a.squeeze(1)], dim=-1)\n",
    "            logits_step = self.fc(comb)\n",
    "            outputs_logits.append(logits_step)\n",
    "            \n",
    "            # Logic mới đã sửa lỗi\n",
    "            if target is not None and random.random() < teach_ratio:\n",
    "                next_input_tokens = target[:, t + 1]\n",
    "            else:\n",
    "                next_input_tokens = logits_step.argmax(-1)\n",
    "\n",
    "            if finished_sequences_tracker is not None:\n",
    "                # Đảm bảo chúng ta không thay thế các chuỗi đã hoàn thành\n",
    "                eos_predicted_this_step = (next_input_tokens == EOS_TOKEN)\n",
    "                finished_sequences_tracker = torch.logical_or(finished_sequences_tracker, eos_predicted_this_step)\n",
    "                \n",
    "                mask = finished_sequences_tracker.long()\n",
    "                eos_token_tensor = torch.tensor(EOS_TOKEN, device=DEVICE, dtype=torch.long).expand_as(next_input_tokens)\n",
    "                current_input_tokens = mask * eos_token_tensor + (1 - mask) * next_input_tokens\n",
    "                if finished_sequences_tracker.all():\n",
    "                    break\n",
    "            else:\n",
    "                current_input_tokens = next_input_tokens\n",
    "        \n",
    "        return torch.stack(outputs_logits, dim=1)\n",
    "\n",
    "#--- Mô hình hoàn chỉnh (YOLO_RViT) ---\n",
    "class YOLO_RViT(nn.Module):\n",
    "    def __init__(self, yolo_path, yolo_target_feature_layer_idx=9):\n",
    "        super().__init__()\n",
    "        self.backbone = YoloBackbone(yolo_path, target_feature_layer_idx=yolo_target_feature_layer_idx)\n",
    "        dummy_input = torch.randn(1, 3, 640, 640).to(DEVICE)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            dummy_feats = self.backbone(dummy_input)\n",
    "        \n",
    "        yolo_channels = dummy_feats.shape[1]\n",
    "        h_feat, w_feat = dummy_feats.shape[2], dummy_feats.shape[3]\n",
    "        num_patches = h_feat * w_feat\n",
    "        \n",
    "        self.rvit = RViT(yolo_channels=yolo_channels, num_patches=num_patches).to(DEVICE)\n",
    "\n",
    "    def forward(self, x, target=None, teach_ratio=0.5, forced_output_length=None):\n",
    "        x = x.to(DEVICE)\n",
    "        feats = self.backbone(x)\n",
    "        return self.rvit(feats, target, teach_ratio, forced_output_length)\n",
    "\n",
    "    def train(self, mode: bool = True):\n",
    "        super().train(mode)\n",
    "        self.rvit.train(mode)\n",
    "        self.backbone.train(mode)\n",
    "        return self\n",
    "\n",
    "    def eval(self):\n",
    "        super().eval()\n",
    "        self.rvit.eval()\n",
    "        self.backbone.eval()\n",
    "        return self\n",
    "\n",
    "#--- Tập dữ liệu ---\n",
    "import albumentations as A\n",
    "import cv2\n",
    "import random\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "IMG_SIZE = 640\n",
    "# Nếu dùng YOLO backbone -> False; nếu không thì True\n",
    "NORMALIZE_FOR_BACKBONE = False\n",
    "\n",
    "# Letterbox đặt CUỐI CÙNG để tránh lộ vùng đệm kỳ dị khi biến đổi hình học\n",
    "_LETTERBOX_LAST = [\n",
    "    A.LongestMaxSize(max_size=IMG_SIZE, interpolation=cv2.INTER_LINEAR, p=1.0),\n",
    "    A.PadIfNeeded(min_height=IMG_SIZE, min_width=IMG_SIZE,\n",
    "                  border_mode=cv2.BORDER_CONSTANT, fill=(114,114,114), p=1.0),\n",
    "    A.ToFloat(max_value=255.0),  # <-- thêm dòng này\n",
    "]\n",
    "\n",
    "def _maybe_norm(normalize: bool):\n",
    "    return [A.Normalize(mean=(0.485,0.456,0.406), std=(0.229,0.224,0.225))] if normalize else []\n",
    "\n",
    "def make_ccpd_aug(subset: str, img_size=IMG_SIZE, normalize=False):\n",
    "    # ----- từng chủ đề/subnet -----\n",
    "    if subset == \"base\":\n",
    "        t = [\n",
    "            A.OneOf([\n",
    "                A.RandomBrightnessContrast(brightness_limit=0.15, contrast_limit=0.15),\n",
    "                A.ColorJitter(brightness=0.15, contrast=0.15, saturation=0.12, hue=0.03),\n",
    "            ], p=0.6),\n",
    "            A.GaussNoise(std_range=(0.005, 0.015), mean_range=(0.0,0.0), p=0.3),\n",
    "        ]\n",
    "    elif subset == \"db\":  # Dark & Bright\n",
    "        t = [\n",
    "            A.OneOf([\n",
    "                A.RandomBrightnessContrast(brightness_limit=0.45, contrast_limit=0.35),\n",
    "                A.RandomGamma(gamma_limit=(60,160)),\n",
    "            ], p=0.9),\n",
    "            A.OneOf([\n",
    "                A.RandomShadow(shadow_roi=(0.05,0.05,0.95,0.95),\n",
    "                               num_shadows_limit=(1,1),          # hoặc (1,2) nếu muốn ngẫu nhiên 1–2 bóng\n",
    "                               shadow_dimension=3,\n",
    "                               shadow_intensity_range=(0.25,0.5)),\n",
    "                A.RandomSunFlare(flare_roi=(0,0,1,0.8),\n",
    "                                 num_flare_circles_range=(2,5),\n",
    "                                 angle_range=(0.0,1.0),\n",
    "                                 src_radius=60),\n",
    "            ], p=0.35),\n",
    "        ]\n",
    "    elif subset == \"blur\":\n",
    "        t = [\n",
    "            A.OneOf([\n",
    "                A.MotionBlur(blur_limit=(5,11)),\n",
    "                A.GaussianBlur(blur_limit=(3,7)),\n",
    "                A.GlassBlur(sigma=0.7, max_delta=3, iterations=1),\n",
    "            ], p=0.9),\n",
    "        ]\n",
    "    elif subset == \"fn\":  # Far & Near\n",
    "        t = [\n",
    "            A.OneOf([\n",
    "                A.Affine(scale=(0.55,0.75), translate_percent=(0.0,0.02),\n",
    "                         rotate=(0,0), shear=(0,0),\n",
    "                         interpolation=cv2.INTER_LINEAR, mask_interpolation=cv2.INTER_NEAREST,\n",
    "                         border_mode=cv2.BORDER_CONSTANT, fill=(114,114,114)),\n",
    "                A.RandomResizedCrop(size=(img_size, img_size),\n",
    "                                    scale=(0.80,1.00), ratio=(0.95,1.05),\n",
    "                                    interpolation=cv2.INTER_LINEAR),\n",
    "            ], p=0.9),\n",
    "            A.OneOf([\n",
    "                A.Downscale(scale_range=(0.60,0.85)),\n",
    "                A.ImageCompression(quality_range=(40,70)),\n",
    "            ], p=0.5),\n",
    "        ]\n",
    "    elif subset == \"rotate\":\n",
    "        t = [\n",
    "            A.Affine(rotate=(-15,15), scale=(0.95,1.05), translate_percent=(0.0,0.04),\n",
    "                     shear=(0,0),\n",
    "                     interpolation=cv2.INTER_LINEAR, mask_interpolation=cv2.INTER_NEAREST,\n",
    "                     border_mode=cv2.BORDER_CONSTANT, fill=(114,114,114), p=1.0),\n",
    "        ]\n",
    "    elif subset == \"tilt\":\n",
    "        t = [\n",
    "            A.Affine(scale=(0.95,1.05), translate_percent=(0.0,0.05),\n",
    "                     rotate=(-3,3), shear=(-18,18),\n",
    "                     interpolation=cv2.INTER_LINEAR, mask_interpolation=cv2.INTER_NEAREST,\n",
    "                     border_mode=cv2.BORDER_CONSTANT, fill=(114,114,114), p=0.8),\n",
    "            A.Perspective(scale=(0.06,0.14), keep_size=True,\n",
    "                          border_mode=cv2.BORDER_CONSTANT, fill=(114,114,114),\n",
    "                          interpolation=cv2.INTER_LINEAR, mask_interpolation=cv2.INTER_NEAREST, p=0.5),\n",
    "        ]\n",
    "    elif subset == \"weather\":\n",
    "        t = [\n",
    "            A.OneOf([\n",
    "                A.RandomFog(fog_coef_range=(0.12,0.28), alpha_coef=0.06),\n",
    "                A.RandomRain(slant_range=(-10,10), drop_length=14, blur_value=3),\n",
    "                A.RandomSnow(snow_point_range=(0.10,0.30), brightness_coeff=1.5),\n",
    "            ], p=0.9),\n",
    "            A.ISONoise(color_shift=(0.01,0.05), intensity=(0.1,0.35), p=0.4),\n",
    "        ]\n",
    "    elif subset == \"challenge\":\n",
    "        t = [\n",
    "            A.OneOf([\n",
    "                A.Affine(scale=(0.90,1.08), translate_percent=(0.0,0.06),\n",
    "                         rotate=(-7,7), shear=(-15,15),\n",
    "                         interpolation=cv2.INTER_LINEAR, mask_interpolation=cv2.INTER_NEAREST,\n",
    "                         border_mode=cv2.BORDER_CONSTANT, fill=(114,114,114)),\n",
    "                A.Perspective(scale=(0.08,0.16), keep_size=True,\n",
    "                              border_mode=cv2.BORDER_CONSTANT, fill=(114,114,114),\n",
    "                              interpolation=cv2.INTER_LINEAR, mask_interpolation=cv2.INTER_NEAREST),\n",
    "            ], p=0.7),\n",
    "            A.OneOf([\n",
    "                A.RandomBrightnessContrast(brightness_limit=0.35, contrast_limit=0.3),\n",
    "                A.RandomGamma(gamma_limit=(70,140)),\n",
    "            ], p=0.8),\n",
    "            A.OneOf([\n",
    "                A.MotionBlur(blur_limit=(3,9)),\n",
    "                A.GaussianBlur(blur_limit=(3,7)),\n",
    "            ], p=0.5),\n",
    "            A.CoarseDropout(num_holes_range=(1,2),           # hoặc (1,3)\n",
    "                            hole_height_range=(0.06,0.12),\n",
    "                            hole_width_range=(0.06,0.12),\n",
    "                            fill=0, p=0.12),\n",
    "        ]\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown subset: {subset}\")\n",
    "\n",
    "    return A.Compose(\n",
    "        [*t, *_LETTERBOX_LAST, *_maybe_norm(normalize), ToTensorV2()],\n",
    "        strict=True\n",
    "    )\n",
    "\n",
    "\n",
    "class CCPDAugmenter:\n",
    "    def __init__(self, img_size=IMG_SIZE, normalize=False, weights=None, fixed_subset=None):\n",
    "        self.img_size = img_size\n",
    "        self.normalize = normalize\n",
    "        # phân phối gần giống “default test” của CCPD; bạn chỉnh tùy ý\n",
    "        self.weights = weights or {\n",
    "            \"base\":0.20, \"db\":0.35, \"blur\":0.10, \"fn\":0.35,\n",
    "            \"rotate\":0.20, \"tilt\":0.20, \"weather\":0.20, \"challenge\":0.35\n",
    "        }\n",
    "        self.fixed_subset = fixed_subset  # nếu muốn khóa 1 subnet\n",
    "\n",
    "    def _sample_subset(self):\n",
    "        if self.fixed_subset is not None:\n",
    "            return self.fixed_subset\n",
    "        names, probs = zip(*self.weights.items())\n",
    "        return random.choices(names, weights=probs, k=1)[0]\n",
    "\n",
    "    def __call__(self, image=None, **kwargs):\n",
    "        if image is None:\n",
    "            image = kwargs.get(\"image\")\n",
    "        subset = self._sample_subset()\n",
    "        tf = make_ccpd_aug(subset, img_size=self.img_size, normalize=self.normalize)\n",
    "        out = tf(image=image)\n",
    "        # có thể gắn kèm tên subnet để debug:\n",
    "        # out[\"subset\"] = subset\n",
    "        return out\n",
    "\n",
    "# === Drop-in thay thế cho train_tf / val_tf trong code của bạn ===\n",
    "train_tf = CCPDAugmenter(img_size=IMG_SIZE, normalize=NORMALIZE_FOR_BACKBONE)\n",
    "val_tf = A.Compose([*_LETTERBOX_LAST, *(_maybe_norm(NORMALIZE_FOR_BACKBONE)), ToTensorV2()],\n",
    "                   strict=True)\n",
    "\n",
    "class LicensePlateDataset(Dataset):\n",
    "    def __init__(self, img_dir, license_dir, max_seq_length=15, is_train=True):\n",
    "        self.img_dir = img_dir\n",
    "        self.license_dir = license_dir\n",
    "        self.max_seq_length = max_seq_length\n",
    "        self.img_names = [f for f in os.listdir(self.img_dir) if f.endswith(('.jpg', '.png'))]\n",
    "        self.is_train = is_train\n",
    "        self.transform = train_tf if is_train else val_tf\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.img_names)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.img_names[idx])\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        # Albumentations nhận ndarray\n",
    "        img_np = np.array(img)\n",
    "        img_tensor = self.transform(image=img_np)[\"image\"]\n",
    "        \n",
    "        license_filename = os.path.splitext(self.img_names[idx])[0] + \".txt\"\n",
    "        license_path = os.path.join(self.license_dir, license_filename)\n",
    "        try:\n",
    "            with open(license_path, 'r', encoding='utf-8') as f:\n",
    "                license_text = f.read().upper().strip()\n",
    "        except FileNotFoundError:\n",
    "            return img_tensor, torch.full((self.max_seq_length,), EOS_TOKEN, dtype=torch.long)\n",
    "        \n",
    "        license_indices = char_to_indices(license_text)\n",
    "        target = torch.full((self.max_seq_length,), PAD_TOKEN, dtype=torch.long)\n",
    "        \n",
    "        actual_len = min(len(license_indices), self.max_seq_length)\n",
    "        target[:actual_len] = license_indices[:actual_len]\n",
    "\n",
    "        return img_tensor, target\n",
    "\n",
    "    @staticmethod\n",
    "    def collate_fn(batch):\n",
    "        images = torch.stack([item[0] for item in batch])\n",
    "        targets = torch.stack([item[1] for item in batch])\n",
    "        return images, targets\n",
    "\n",
    "#--- Dừng sớm (Early Stopping) ---\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=10, min_delta=0.0, monitor_metric='val_acc', mode='max', verbose=True):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.monitor_metric = monitor_metric\n",
    "        self.mode = mode\n",
    "        self.verbose = verbose\n",
    "\n",
    "        if self.mode == 'min':\n",
    "            self.best_metric_val = np.Inf\n",
    "        else:\n",
    "            self.best_metric_val = -np.Inf\n",
    "        self.counter = 0\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, current_metric_val):\n",
    "        improved = False\n",
    "        if self.mode == 'min':\n",
    "            if current_metric_val < self.best_metric_val - self.min_delta:\n",
    "                self.best_metric_val = current_metric_val\n",
    "                improved = True\n",
    "        else:\n",
    "            if current_metric_val > self.best_metric_val + self.min_delta:\n",
    "                self.best_metric_val = current_metric_val\n",
    "                improved = True\n",
    "        \n",
    "        if improved:\n",
    "            self.counter = 0\n",
    "            if self.verbose:\n",
    "                print(f\"EarlyStopping: New best {self.monitor_metric}: {self.best_metric_val:.4f}\")\n",
    "        else:\n",
    "            self.counter += 1\n",
    "\n",
    "        if self.verbose and self.counter > 0 and not improved:\n",
    "            print(f\"EarlyStopping counter: {self.counter}/{self.patience} (Best {self.monitor_metric}: {self.best_metric_val:.4f})\")\n",
    "        if self.counter >= self.patience:\n",
    "            self.early_stop = True\n",
    "            if self.verbose:\n",
    "                print(f\"Early stopping triggered for {self.monitor_metric}.\")\n",
    "        return self.counter\n",
    "\n",
    "#--- Huấn luyện ---\n",
    "YOLO_MODEL_PATH = '/kaggle/input/yolov11s/pytorch/default/1/best.pt'\n",
    "YOLO_TARGET_FEATURE_LAYER_INDEX = 13\n",
    "\n",
    "# IMG_DIR_TRAIN = \"/kaggle/input/aolp-ac-1/AOLP_AC/Images/Train\"\n",
    "# LICENSE_DIR_TRAIN = \"/kaggle/input/aolp-ac-1/AOLP_AC/Text/Train\"\n",
    "\n",
    "IMG_DIR_VAL = \"/kaggle/input/clpd-dataset/CLPD/image\"\n",
    "LICENSE_DIR_VAL = \"/kaggle/input/clpd-dataset/CLPD/text\"\n",
    "\n",
    "# IMG_DIR_TEST = \"/kaggle/input/pku-g1/G1/G1_lp_images\"\n",
    "# LICENSE_DIR_TEST = \"/kaggle/input/pku-g1/G1/G1_lp_images\"\n",
    "\n",
    "MAX_SEQ_LENGTH = 15\n",
    "BATCH_SIZE = 8\n",
    "NUM_WORKERS = 4\n",
    "LEARNING_RATE = 5e-5\n",
    "MAX_LR_SCHEDULER = 5e-4\n",
    "WEIGHT_DECAY = 5e-5\n",
    "NUM_EPOCHS = 1\n",
    "ACCUM_STEPS = 2\n",
    "PATIENCE_EARLY_STOP = 200\n",
    "TEACH_RATIO_START = 0.7\n",
    "TEACH_RATIO_END = 0.05\n",
    "LABEL_SMOOTHING = 0.01\n",
    "scaler = torch.amp.GradScaler('cuda')\n",
    "autocast_context = lambda: torch.amp.autocast('cuda')\n",
    "\n",
    "# train_dataset_full = LicensePlateDataset(img_dir=IMG_DIR_TRAIN, license_dir=LICENSE_DIR_TRAIN, max_seq_length=MAX_SEQ_LENGTH, is_train=True)\n",
    "val_dataset = LicensePlateDataset(img_dir=IMG_DIR_VAL, license_dir=LICENSE_DIR_VAL, max_seq_length=MAX_SEQ_LENGTH, is_train=False)\n",
    "# test_dataset = LicensePlateDataset(img_dir=IMG_DIR_TEST, license_dir=LICENSE_DIR_TEST, max_seq_length=MAX_SEQ_LENGTH, is_train=False)\n",
    "\n",
    "# train_dataloader = DataLoader(train_dataset_full, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS, collate_fn=LicensePlateDataset.collate_fn, pin_memory=(DEVICE == 'cuda'), drop_last=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, collate_fn=LicensePlateDataset.collate_fn, pin_memory=(DEVICE == 'cuda'))\n",
    "# test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, collate_fn=LicensePlateDataset.collate_fn, pin_memory=(DEVICE == 'cuda'))\n",
    "\n",
    "model = YOLO_RViT(YOLO_MODEL_PATH, yolo_target_feature_layer_idx=YOLO_TARGET_FEATURE_LAYER_INDEX).to(DEVICE)\n",
    "\n",
    "optimizer = bnb_optim.AdamW8bit(\n",
    "    model.parameters(),\n",
    "    lr=LEARNING_RATE,\n",
    "    weight_decay=WEIGHT_DECAY)\n",
    "\n",
    "# scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "#     optimizer, max_lr=MAX_LR_SCHEDULER,\n",
    "#     # epochs=NUM_EPOCHS,\n",
    "#     # steps_per_epoch=(len(train_dataloader) + ACCUM_STEPS - 1) // ACCUM_STEPS,\n",
    "#     pct_start=0.2,\n",
    "#     div_factor=(MAX_LR_SCHEDULER / LEARNING_RATE) if MAX_LR_SCHEDULER > LEARNING_RATE else 10.0)\n",
    "\n",
    "scheduler_type = \"OneCycleLR\"\n",
    "loss_fn = nn.CrossEntropyLoss(ignore_index=PAD_TOKEN, label_smoothing=LABEL_SMOOTHING)\n",
    "early_stopper = EarlyStopping(patience=PATIENCE_EARLY_STOP, min_delta=0.0005, monitor_metric='val_acc', mode='max', verbose=True)\n",
    "\n",
    "checkpoint = torch.load(\"/kaggle/input/ccpd_base_good/pytorch/default/1/CCPD_BASE_GOOD.pth\", map_location=DEVICE)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "\n",
    "train_loss_values, val_loss_values, test_loss_values = [], [], []\n",
    "train_acc_values, val_acc_values, val_acc_constrained_values, test_acc_values, test_acc_constrained_values = [], [], [], [], []\n",
    "epoch_count_list = []\n",
    "best_val_acc = 0.0\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    epoch_count_list.append(epoch + 1)\n",
    "    # model.train()\n",
    "    # train_loss, train_correct, train_total_chars = 0, 0, 0\n",
    "\n",
    "    teach_ratio = TEACH_RATIO_START - (TEACH_RATIO_START - TEACH_RATIO_END) * (epoch / max(1, NUM_EPOCHS - 1))\n",
    "\n",
    "    # optimizer.zero_grad()\n",
    "\n",
    "    # pbar_train = tqdm(train_dataloader, desc=f\"Epoch {epoch+1}/{NUM_EPOCHS} [TRAIN] LR: {optimizer.param_groups[0]['lr']:.2e} Teach: {teach_ratio:.2f} Scheduler: {scheduler_type}\")\n",
    "    # for batch_idx, (imgs, targets) in enumerate(pbar_train):\n",
    "    #     imgs, targets = imgs.to(DEVICE, non_blocking=True), targets.to(DEVICE, non_blocking=True)\n",
    "        \n",
    "    #     with autocast_context():\n",
    "    #         outputs = model(imgs, target=targets, teach_ratio=teach_ratio)\n",
    "    #         flat_outputs = outputs.reshape(-1, NUM_CLASSES)\n",
    "    #         flat_targets = targets[:, 1:].reshape(-1)\n",
    "    #         loss = loss_fn(flat_outputs, flat_targets)\n",
    "    #         loss = loss / ACCUM_STEPS\n",
    "            \n",
    "    #     scaler.scale(loss).backward()\n",
    "        \n",
    "    #     if (batch_idx + 1) % ACCUM_STEPS == 0 or (batch_idx + 1) == len(train_dataloader):\n",
    "    #         torch.nn.utils.clip_grad_norm_(filter(lambda p: p.requires_grad, model.parameters()), max_norm=1.0)\n",
    "    #         scaler.step(optimizer)\n",
    "    #         scaler.update()\n",
    "    #         optimizer.zero_grad()\n",
    "    #         if scheduler_type == \"OneCycleLR\":\n",
    "    #             scheduler.step()\n",
    "\n",
    "    #     train_loss += loss.item() * ACCUM_STEPS\n",
    "    #     with torch.no_grad():\n",
    "    #         preds = outputs.argmax(-1)\n",
    "    #         true_chars = targets[:, 1:]\n",
    "    #         for i in range(imgs.size(0)):\n",
    "    #             pred_seq_list_train = preds[i].tolist()\n",
    "    #             if EOS_TOKEN in pred_seq_list_train:\n",
    "    #                 pred_seq_list_train = pred_seq_list_train[:pred_seq_list_train.index(EOS_TOKEN)]\n",
    "                \n",
    "    #             true_seq_list_train = true_chars[i].tolist()\n",
    "    #             true_content_train = [x for x in true_seq_list_train if x not in [EOS_TOKEN, PAD_TOKEN]]\n",
    "    #             len_true_content_train = len(true_content_train)\n",
    "                \n",
    "    #             cmp_len = min(len(pred_seq_list_train), len_true_content_train)\n",
    "    #             if cmp_len > 0:\n",
    "    #                 train_correct += (torch.tensor(pred_seq_list_train[:cmp_len]) == torch.tensor(true_content_train[:cmp_len])).sum().item()\n",
    "                \n",
    "    #             train_total_chars += len_true_content_train\n",
    "\n",
    "    #         if batch_idx == 0 and epoch % 1 == 0 and imgs.size(0) > 0:\n",
    "    #             print(\"\\n--- Ví dụ Batch 0 trong quá trình Huấn luyện ---\")\n",
    "    #             for i in range(min(5, imgs.size(0))):\n",
    "    #                 pred_batch_i_list = preds[i].tolist()\n",
    "    #                 pred_example = index_to_char(pred_batch_i_list)\n",
    "    #                 true_batch_i_list = true_chars[i].tolist()\n",
    "    #                 true_example = index_to_char(true_batch_i_list)\n",
    "    #                 print(f\"  Dự đoán: '{pred_example}'\")\n",
    "    #                 print(f\"  Thực tế: '{true_example}'\")\n",
    "    #             print(\"-------------------------------\")\n",
    "        \n",
    "    #     pbar_train.set_postfix(loss=loss.item() * ACCUM_STEPS)\n",
    "\n",
    "    # avg_train_loss = train_loss / len(train_dataloader) if len(train_dataloader) > 0 else 0\n",
    "    # avg_train_acc = train_correct / train_total_chars if train_total_chars > 0 else 0\n",
    "    # train_loss_values.append(avg_train_loss)\n",
    "    # train_acc_values.append(avg_train_acc)\n",
    "\n",
    "    # --- Vòng lặp kiểm tra (Validation) ---\n",
    "    model.eval()\n",
    "    val_loss, val_correct, val_total_chars, val_exact_match_correct, val_total_sequences = 0, 0, 0, 0, 0\n",
    "    pbar_val = tqdm(val_dataloader, desc=f\"Epoch {epoch+1}/{NUM_EPOCHS} [VAL]\")\n",
    "    with torch.no_grad():\n",
    "        for imgs, targets in pbar_val:\n",
    "            imgs, targets = imgs.to(DEVICE, non_blocking=True), targets.to(DEVICE, non_blocking=True)\n",
    "            with autocast_context():\n",
    "                outputs = model(imgs, target=None, teach_ratio=0.0)\n",
    "                out_seq_len_val = outputs.size(1)\n",
    "                tgt_content_len_val = targets.size(1) - 1\n",
    "                \n",
    "                # Cắt bớt hoặc đệm đầu ra để tính toán loss\n",
    "                if out_seq_len_val > tgt_content_len_val:\n",
    "                    outputs_for_loss_val = outputs[:, :tgt_content_len_val, :]\n",
    "                elif out_seq_len_val < tgt_content_len_val:\n",
    "                    padding_val_val = torch.zeros(outputs.size(0), tgt_content_len_val - out_seq_len_val, NUM_CLASSES, device=DEVICE)\n",
    "                    padding_val_val[:,:,PAD_TOKEN] = 1\n",
    "                    outputs_for_loss_val = torch.cat([outputs, padding_val_val], dim=1)\n",
    "                else:\n",
    "                    outputs_for_loss_val = outputs\n",
    "\n",
    "                flat_outputs_val = outputs_for_loss_val.reshape(-1, NUM_CLASSES)\n",
    "                flat_targets_val = targets[:, 1:].reshape(-1)\n",
    "                loss = loss_fn(flat_outputs_val, flat_targets_val)\n",
    "                \n",
    "            val_loss += loss.item()\n",
    "            preds_val = outputs.argmax(-1)           # [B, T]\n",
    "            true_chars_val = targets[:, 1:]          # bỏ SOS ở đầu\n",
    "            \n",
    "            for i in range(imgs.size(0)):\n",
    "                # --- Chuỗi dự đoán (cắt tại EOS, KHÔNG lọc theo giá trị token) ---\n",
    "                pred_seq_full = preds_val[i].tolist()\n",
    "                if EOS_TOKEN in pred_seq_full:\n",
    "                    pred_seq_full = pred_seq_full[:pred_seq_full.index(EOS_TOKEN)]\n",
    "            \n",
    "                # --- Chuỗi GT (bỏ EOS/PAD) ---\n",
    "                true_seq_full = true_chars_val[i].tolist()\n",
    "                true_content  = [x for x in true_seq_full if x not in [EOS_TOKEN, PAD_TOKEN]]\n",
    "            \n",
    "                # Căn theo độ dài khả dụng để so sánh theo vị trí\n",
    "                cmp_len = min(len(pred_seq_full), len(true_content))\n",
    "                pred_cmp = pred_seq_full[:cmp_len]\n",
    "                gt_cmp   = true_content[:cmp_len]\n",
    "            \n",
    "                # Chỉ lấy các vị trí mà GT KHÔNG phải Chinese\n",
    "                non_cn_pos = [t for t, tk in enumerate(gt_cmp) if not is_chinese_idx(tk)]\n",
    "            \n",
    "                # --- Character-level accuracy (KHÔNG tính ký tự Chinese) ---\n",
    "                if non_cn_pos:\n",
    "                    val_correct += sum(int(pred_cmp[t] == gt_cmp[t]) for t in non_cn_pos)\n",
    "                    val_total_chars += len(non_cn_pos)\n",
    "            \n",
    "                # --- Exact-match trên phần non-Chinese ---\n",
    "                # Lấy chuỗi con theo đúng các vị trí non-Chinese của GT\n",
    "                gt_non_cn   = [gt_cmp[t] for t in non_cn_pos]\n",
    "                pred_non_cn = [pred_cmp[t] for t in non_cn_pos]\n",
    "            \n",
    "                # Chỉ tính E2E nếu có ít nhất 1 ký tự non-Chinese để đánh giá\n",
    "                if gt_non_cn:\n",
    "                    val_total_sequences += 1\n",
    "                    if pred_non_cn == gt_non_cn:\n",
    "                        val_exact_match_correct += 1\n",
    "\n",
    "\n",
    "            \n",
    "            pbar_val.set_postfix(loss=loss.item())\n",
    "\n",
    "    avg_val_loss = val_loss / len(val_dataloader) if len(val_dataloader) > 0 else 0\n",
    "    avg_val_acc = val_correct / val_total_chars if val_total_chars > 0 else 0\n",
    "    val_exact_match_acc = val_exact_match_correct / val_total_sequences if val_total_sequences > 0 else 0\n",
    "    val_loss_values.append(avg_val_loss)\n",
    "    val_acc_values.append(avg_val_acc)\n",
    "    val_acc_constrained_values.append(val_exact_match_acc)\n",
    "    \n",
    "    # # Chuyển sang ReduceLROnPlateau nếu val_acc chững lại\n",
    "    # early_stopper_val_result = early_stopper(avg_val_acc)\n",
    "    # if early_stopper_val_result >= 30 and scheduler_type == \"OneCycleLR\":\n",
    "    #     print(f\"Độ chính xác kiểm tra chững lại trong 50 epoch. Chuyển sang ReduceLROnPlateau.\")\n",
    "    #     scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=5, verbose=True)\n",
    "    #     scheduler_type = \"ReduceLROnPlateau\"\n",
    "    \n",
    "    # # Cập nhật scheduler\n",
    "    # if scheduler_type == \"ReduceLROnPlateau\":\n",
    "    #     scheduler.step(avg_val_acc)\n",
    "\n",
    "    # if early_stopper.early_stop:\n",
    "    #     print(f\"--> Dừng sớm tại epoch {epoch+1}\")\n",
    "    #     break\n",
    "    \n",
    "    print(f\"\\nEpoch {epoch+1}/{NUM_EPOCHS} | LR: {optimizer.param_groups[0]['lr']:.2e} | Teach: {teach_ratio:.2f} | Scheduler: {scheduler_type}\")\n",
    "    # print(f\"  Train Loss: {avg_train_loss:.4f} | Train Acc Ký tự: {avg_train_acc:.4f}\")\n",
    "    print(f\"  Val Loss: {avg_val_loss:.4f}   | Val Acc Ký tự: {avg_val_acc:.4f}\")\n",
    "    print(f\"  Test Acc Khớp chính xác (Toàn bộ chuỗi): {val_exact_match_acc:.4f}\")\n",
    "    print(\"-\" * 70)\n",
    "\n",
    "    # if avg_val_acc > best_val_acc:\n",
    "    #     best_val_acc = avg_val_acc\n",
    "    #     print(f\"*** Độ chính xác kiểm tra tốt nhất mới: {best_val_acc:.4f}. Đang lưu best_model.pth ***\")\n",
    "    #     torch.save({\n",
    "    #         'epoch': epoch,\n",
    "    #         'model_state_dict': model.state_dict(),\n",
    "    #         'optimizer_state_dict': optimizer.state_dict(),\n",
    "    #         'scheduler_state_dict': scheduler.state_dict(),\n",
    "    #         'val_loss': avg_val_loss,\n",
    "    #         'val_acc': avg_val_acc,\n",
    "    #         'val_exact_match_acc': val_exact_match_acc,\n",
    "    #     }, \"best_yolo_rvit_model.pth\")\n",
    "        \n",
    "# final_epoch_val = epoch if 'epoch' in locals() and epoch is not None else NUM_EPOCHS - 1\n",
    "# torch.save({\n",
    "#     'epoch': final_epoch_val,\n",
    "#     'model_state_dict': model.state_dict(),\n",
    "#     'optimizer_state_dict': optimizer.state_dict(),\n",
    "#     'scheduler_state_dict': scheduler.state_dict(),\n",
    "#     'train_loss_history': train_loss_values,\n",
    "#     'val_loss_history': val_loss_values,\n",
    "#     'train_acc_history': train_acc_values,\n",
    "#     'val_acc_history': val_acc_values,\n",
    "#     'val_exact_match_acc_history': val_acc_constrained_values,}, \"final_yolo_rvit_model.pth\")\n",
    "\n",
    "print(\"\\nQuá trình huấn luyện đã hoàn thành!\")\n",
    "if val_acc_values:\n",
    "    print(f\"Độ chính xác kiểm tra cuối cùng (Cấp độ ký tự): {val_acc_values[-1]:.4f}\")\n",
    "if val_acc_constrained_values:\n",
    "    print(f\"Độ chính xác khớp chính xác cuối cùng: {val_acc_constrained_values[-1]:.4f}\")\n",
    "\n",
    "# # Vẽ đồ thị\n",
    "# plt.figure(figsize=(18, 12))\n",
    "# plt.subplot(2, 2, 1)\n",
    "# plt.plot(epoch_count_list, train_loss_values, label='Train Loss', marker='o', linestyle='-')\n",
    "# plt.plot(epoch_count_list, val_loss_values, label='Validation Loss', marker='s', linestyle='--')\n",
    "# plt.title('Loss Curves')\n",
    "# plt.xlabel('Epochs')\n",
    "# plt.ylabel('Loss')\n",
    "# plt.legend()\n",
    "# plt.grid(True)\n",
    "# plt.subplot(2, 2, 2)\n",
    "# plt.plot(epoch_count_list, train_acc_values, label='Train Char Accuracy', marker='o', linestyle='-')\n",
    "# plt.plot(epoch_count_list, val_acc_values, label='Validation Char Accuracy (Greedy)', marker='s', linestyle='--')\n",
    "# plt.title('Character Accuracy')\n",
    "# plt.xlabel('Epochs')\n",
    "# plt.ylabel('Character Accuracy')\n",
    "# plt.legend()\n",
    "# plt.grid(True)\n",
    "# plt.tight_layout()\n",
    "# plt.savefig(\"performance_plots.png\")\n",
    "# plt.show()\n",
    "# print(\"Đã lưu đồ thị vào performance_plots.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae0cc0b2",
   "metadata": {
    "_cell_guid": "21d45f97-e23d-4863-9eaf-d412c4a273c0",
    "_uuid": "77995164-735b-4219-9421-582b5ba16f4f",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-09-30T08:07:55.772352Z",
     "iopub.status.busy": "2025-09-30T08:07:55.771694Z",
     "iopub.status.idle": "2025-09-30T08:07:55.775867Z",
     "shell.execute_reply": "2025-09-30T08:07:55.775334Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.039556,
     "end_time": "2025-09-30T08:07:55.776896",
     "exception": false,
     "start_time": "2025-09-30T08:07:55.737340",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from ultralytics import YOLO\n",
    "\n",
    "# def print_yolo_modules(model_path):\n",
    "#     \"\"\"\n",
    "#     Tải một mô hình YOLO và in ra các module (lớp) của nó.\n",
    "#     :param model_path: Đường dẫn đến file .pt của mô hình YOLO.\n",
    "#     \"\"\"\n",
    "#     try:\n",
    "#         # Tải một mô hình YOLOv8 đã được huấn luyện sẵn\n",
    "#         print(f\"Đang tải mô hình YOLO từ: {model_path}\")\n",
    "#         yolo_model = YOLO(model_path)\n",
    "        \n",
    "#         # Truy cập vào kiến trúc mô hình.\n",
    "#         # Các module được lưu trong một list Python tại yolo_model.model.model\n",
    "#         modules = yolo_model.model.model\n",
    "        \n",
    "#         print(\"\\n--- Cấu trúc mô hình YOLOv8 ---\")\n",
    "#         # Lặp qua từng module và in thông tin\n",
    "#         for i, layer in enumerate(modules):\n",
    "#             # In chỉ số, tên lớp và các tham số của module đó\n",
    "#             print(f\"Layer {i}: {layer.__class__.__name__}\")\n",
    "#             print(f\"  - Parameters: {sum(p.numel() for p in layer.parameters()):,} trainable\")\n",
    "#             print(f\"  - Details: {layer}\")\n",
    "        \n",
    "#         print(\"---------------------------------\")\n",
    "#         print(\"Kết thúc việc in cấu trúc mô hình.\")\n",
    "\n",
    "#     except Exception as e:\n",
    "#         print(f\"Lỗi: Không thể tải hoặc xử lý mô hình. Vui lòng kiểm tra đường dẫn '{model_path}' và đảm bảo bạn đã cài đặt 'ultralytics' đúng cách.\")\n",
    "#         print(f\"Chi tiết lỗi: {e}\")\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     # Thay đổi đường dẫn này nếu bạn muốn kiểm tra một mô hình khác\n",
    "#     model_path_to_inspect = '/kaggle/input/yolo_v11s_ac/pytorch/default/1/best.pt'\n",
    "#     print_yolo_modules(model_path_to_inspect)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 7283240,
     "sourceId": 11903981,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8288745,
     "sourceId": 13086476,
     "sourceType": "datasetVersion"
    },
    {
     "isSourceIdPinned": false,
     "modelId": 357248,
     "modelInstanceId": 336244,
     "sourceId": 411841,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": false,
     "modelId": 360753,
     "modelInstanceId": 339649,
     "sourceId": 416302,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": false,
     "modelId": 407181,
     "modelInstanceId": 388179,
     "sourceId": 486758,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": false,
     "modelId": 408151,
     "modelInstanceId": 389282,
     "sourceId": 488649,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": false,
     "modelId": 408751,
     "modelInstanceId": 389919,
     "sourceId": 490251,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": false,
     "modelId": 430792,
     "modelInstanceId": 413054,
     "sourceId": 528025,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": false,
     "modelId": 435067,
     "modelInstanceId": 417380,
     "sourceId": 538127,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": false,
     "modelId": 443641,
     "modelInstanceId": 426171,
     "sourceId": 564198,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": false,
     "modelId": 447061,
     "modelInstanceId": 430119,
     "sourceId": 574685,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": false,
     "modelId": 448180,
     "modelInstanceId": 431253,
     "sourceId": 576860,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": false,
     "modelId": 448639,
     "modelInstanceId": 431731,
     "sourceId": 577962,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": false,
     "modelId": 455410,
     "modelInstanceId": 438838,
     "sourceId": 587082,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 461074,
     "modelInstanceId": 444586,
     "sourceId": 594029,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 140.061459,
   "end_time": "2025-09-30T08:07:58.272231",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-09-30T08:05:38.210772",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
